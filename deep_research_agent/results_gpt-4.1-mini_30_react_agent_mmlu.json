{
  "generated_text": "The staff members for the Carnegie Mellon University (CMU) course 11-763, titled \"Inference Algorithms for Language Modeling,\" for the Fall 2025 semester are:\n\n1. **Graham Neubig** - Primary Instructor\n   - Email: [gneubig@cs.cmu.edu](mailto:gneubig@cs.cmu.edu)\n   - Graham Neubig is an associate professor at the Language Technologies Institute, specializing in natural language processing.\n\n2. **Amanda Bertsch**",
  "total_tokens": 2096,
  "tool_call_count": 0,
  "stopped_reason": "max_tokens",
  "tool_calls": [
    {
      "generated_text": "I currently do not have specific information regarding the staff members for the CMU 11-763 Inference Algorithms for Language Modeling classes. I need to consider the following points to systematically address this question:\n\n1. **Previous Searches**: There has been no prior search or information provided regarding the staff members for this course. I lack any information about the instructors, teaching assistants, or any other faculty involved.\n\n2. **Missing Key Information**: The key pieces of information that are missing include the names of the primary instructor(s), any teaching assistants, their roles, and possibly their contact information or office hours. This information is crucial for students or individuals interested in the course to understand who they might interact with.\n\n3. **Helpful Next Search**: To find this information, I should search for the official course webpage or the relevant department's website at Carnegie Mellon University (CMU). This search should include keywords such as \"CMU 11-763 Inference Algorithms for Language Modeling staff,\" \"CMU 11-763 course information,\" or \"CMU Language Modeling course instructor.\" Additionally, I might want to check for any announcements related to the course or academic calendars that may list staff members.\n\n4. **How This Search Will Help**: Performing this search will help me gather the specific names and roles of the staff members associated with the CMU 11-763 course, directly answering the original question. This information will be beneficial for anyone looking for guidance or support in relation to the course.\n\nOverall, the next logical step is to locate the official course or department website to find the staff information for CMU 11-763.</think>",
      "total_tokens": 497,
      "tool_call_count": 0,
      "stopped_reason": "natural",
      "tool_calls": []
    },
    {
      "generated_text": "<query>CMU 11-763 Inference Algorithms for Language Modeling course staff instructors teaching assistants</query><snippet id=69d673a1>\nTitle: 11-664/763: Inference Algorithms for Language Modeling\nURL: https://www.phontron.com/class/lminference-fall2025/\nSnippet: Students will understand the different ways to implement and compare inference-time techniques, learn the theory behind different strategies for inference-time ...\n\nTitle: CMU LLM Inference (1): Introduction to Language Models and ...\nURL: https://www.youtube.com/watch?v=F-mduXzNcRQ\nSnippet: This lecture (by Graham Neubig) for CMU CS 11-763, Advanced NLP (Fall 2025) covers: What is a language model? What is an inference algorithm ...\n</snippet><query>CMU 11-763 Inference Algorithms for Language Modeling staff list site:phontron.com</query><snippet id=f86c4442>\nTitle: 11-664/763: Inference Algorithms for Language Modeling\nURL: https://www.phontron.com/class/lminference-fall2025/\nSnippet: 11-664/763: Inference Algorithms for Language Modeling. Fall 2025 @ Carnegie Mellon University. Graham Neubig \u00b7 gneubig@cs.cmu.edu \u00b7 Amanda Bertsch \u00b7 abertsch@ ...\n</snippet><query>CMU 11-763 Inference Algorithms for Language Modeling staff members Graham Neubig Amanda Bertsch</query><snippet id=be20b276>\nTitle: 11-664/763: Inference Algorithms for Language Modeling\nURL: https://www.phontron.com/class/lminference-fall2025/\nSnippet: A class at Carnegie Mellon University on language model inference algorithms ... Graham Neubig \u00b7 gneubig@cs.cmu.edu \u00b7 Amanda Bertsch \u00b7 abertsch@cs.cmu.edu. Course ...\n\nTitle: Learn Inference Algorithms for Language Modeling at CMU - LinkedIn\nURL: https://www.linkedin.com/posts/kelvinmeeks_11-663763-lm-inference-activity-7341239778308214786-5NXw\nSnippet: ... Carnegie Mellon University Taught by Graham Neubig, and Amanda Bertsch \"Inference-time algorithms can allow users to run models on their ...\n</snippet><query>CMU 11-763 Inference Algorithms for Language Modeling instructors Graham Neubig Amanda Bertsch contact</query><snippet id=1303dd4c>\nTitle: 11-664/763: Inference Algorithms for Language Modeling\nURL: https://www.phontron.com/class/lminference-fall2025/\nSnippet: Graham Neubig \u00b7 gneubig@cs.cmu.edu \u00b7 Amanda Bertsch \u00b7 abertsch@cs.cmu.edu. Course ... classes of inference-time algorithms. In the final project, students ...\n\nTitle: Amanda Bertsch - CMU School of Computer Science\nURL: https://www.cs.cmu.edu/~abertsch/\nSnippet: I am a PhD student in the Language Technologies Institute at Carnegie Mellon University, advised by Matt Gormley and Graham Neubig.\n</snippet><query>CMU 11-763 Inference Algorithms for Language Modeling course staff Graham Neubig Amanda Bertsch email</query><snippet id=4ee09327>\nTitle: 11-664/763: Inference Algorithms for Language Modeling\nURL: https://www.phontron.com/class/lminference-fall2025/\nSnippet: A class at Carnegie Mellon University on language model inference algorithms ... Graham Neubig \u00b7 gneubig@cs.cmu.edu \u00b7 Amanda Bertsch \u00b7 abertsch@cs.cmu.edu ...\n\nTitle: Amanda Bertsch - CMU School of Computer Science\nURL: https://www.cs.cmu.edu/~abertsch/\nSnippet: I am a PhD student in the Language Technologies Institute at Carnegie Mellon University, advised by Matt Gormley and Graham Neubig.\n</snippet><query>CMU 11-763 Inference Algorithms for Language Modeling faculty contact information Graham Neubig Amanda Bertsch</query><snippet id=ef07d6da>\nTitle: 11-664/763: Inference Algorithms for Language Modeling\nURL: https://www.phontron.com/class/lminference-fall2025/\nSnippet: Graham Neubig \u00b7 gneubig@cs.cmu.edu \u00b7 Amanda Bertsch \u00b7 abertsch@cs.cmu.edu. Course ... Course Information. Prerequisites: 11-411/611/711 OR 11-785 OR 10-401/601 ...\n\nTitle: Amanda Bertsch - CMU School of Computer Science\nURL: https://www.cs.cmu.edu/~abertsch/\nSnippet: I am a PhD student in the Language Technologies Institute at Carnegie Mellon University, advised by Matt Gormley and Graham Neubig.\n</snippet><query>CMU 11-763 Inference Algorithms for Language Modeling staff members Graham Neubig Amanda Bertsch course details</query><snippet id=30101cdd>\nTitle: 11-664/763: Inference Algorithms for Language Modeling\nURL: https://www.phontron.com/class/lminference-fall2025/\nSnippet: In this class, we survey the wide space of inference-time techniques with a particular focus on the implementation and practical use cases of such methods.\n\nTitle: Learn Inference Algorithms for Language Modeling at CMU - LinkedIn\nURL: https://www.linkedin.com/posts/kelvinmeeks_11-663763-lm-inference-activity-7341239778308214786-5NXw\nSnippet: Noteworthy: 11-663/763: Inference Algorithms for Language Modeling Fall 2025 Carnegie Mellon University Taught by Graham Neubig, and Amanda ...\n</snippet><query>CMU 11-763 Inference Algorithms for Language Modeling course staff instructors Graham Neubig Amanda Bertsch</query><snippet id=68079351>\nTitle: 11-664/763: Inference Algorithms for Language Modeling\nURL: https://www.phontron.com/class/lminference-fall2025/\nSnippet: A class at Carnegie Mellon University on language model inference algorithms ... Graham Neubig \u00b7 gneubig@cs.cmu.edu \u00b7 Amanda Bertsch \u00b7 abertsch@cs.cmu.edu. Course ...\n\nTitle: Graham Neubig - Language Technologies Institute\nURL: https://www.lti.cs.cmu.edu/people/faculty/neubig-graham.html\nSnippet: Graham Neubig is an associate professor at the Language Technologies Institute of Carnegie Mellon University. His research focuses on natural language ...\n</snippet><query>CMU 11-763 Inference Algorithms for Language Modeling faculty Graham Neubig Amanda Bertsch information</query><snippet id=6309c263>\nTitle: 11-664/763: Inference Algorithms for Language Modeling\nURL: https://www.phontron.com/class/lminference-fall2025/\nSnippet: A class at Carnegie Mellon University on language model inference algorithms ... Graham Neubig \u00b7 gneubig@cs.cmu.edu \u00b7 Amanda Bertsch \u00b7 abertsch@cs.cmu.edu. Course ...\n\nTitle: Graham Neubig - Language Technologies Institute\nURL: https://www.lti.cs.cmu.edu/people/faculty/neubig-graham.html\nSnippet: Graham Neubig is an associate professor at the Language Technologies Institute of Carnegie Mellon University. His research focuses on natural language ...\n</snippet>",
      "total_tokens": 2156,
      "tool_call_count": 9,
      "stopped_reason": "max_tokens",
      "tool_calls": [
        {
          "tool_name": "ChainedTool",
          "output": "Title: 11-664/763: Inference Algorithms for Language Modeling\nURL: https://www.phontron.com/class/lminference-fall2025/\nSnippet: Students will understand the different ways to implement and compare inference-time techniques, learn the theory behind different strategies for inference-time ...\n\nTitle: CMU LLM Inference (1): Introduction to Language Models and ...\nURL: https://www.youtube.com/watch?v=F-mduXzNcRQ\nSnippet: This lecture (by Graham Neubig) for CMU CS 11-763, Advanced NLP (Fall 2025) covers: What is a language model? What is an inference algorithm ...",
          "called": true,
          "timeout": false,
          "runtime": 5.747374057769775,
          "error": "",
          "call_id": "69d673a1",
          "raw_output": {
            "tool_outputs": [
              {
                "tool_name": "SerperSearchTool",
                "output": "Title: 11-664/763: Inference Algorithms for Language Modeling\nURL: https://www.phontron.com/class/lminference-fall2025/\nSnippet: Students will understand the different ways to implement and compare inference-time techniques, learn the theory behind different strategies for inference-time ...\n\nTitle: CMU LLM Inference (1): Introduction to Language Models and ...\nURL: https://www.youtube.com/watch?v=F-mduXzNcRQ\nSnippet: This lecture (by Graham Neubig) for CMU CS 11-763, Advanced NLP (Fall 2025) covers: What is a language model? What is an inference algorithm ...",
                "called": true,
                "timeout": false,
                "runtime": 1.002558946609497,
                "error": "",
                "call_id": "e992bfcc",
                "raw_output": {
                  "searchParameters": {
                    "q": "<query>CMU 11-763 Inference Algorithms for Language Modeling course staff instructors teaching assistants",
                    "gl": "us",
                    "hl": "en",
                    "type": "search",
                    "num": 2,
                    "engine": "google"
                  },
                  "organic": [
                    {
                      "title": "11-664/763: Inference Algorithms for Language Modeling",
                      "link": "https://www.phontron.com/class/lminference-fall2025/",
                      "snippet": "Students will understand the different ways to implement and compare inference-time techniques, learn the theory behind different strategies for inference-time ...",
                      "attributes": {
                        "Missing": "<query> instructors teaching assistants"
                      },
                      "position": 1
                    },
                    {
                      "title": "CMU LLM Inference (1): Introduction to Language Models and ...",
                      "link": "https://www.youtube.com/watch?v=F-mduXzNcRQ",
                      "snippet": "This lecture (by Graham Neubig) for CMU CS 11-763, Advanced NLP (Fall 2025) covers: What is a language model? What is an inference algorithm ...",
                      "date": "Sep 11, 2025",
                      "attributes": {
                        "Missing": "<query> staff teaching assistants"
                      },
                      "position": 2
                    }
                  ],
                  "relatedSearches": [
                    {
                      "query": "CMU NLP Professor"
                    },
                    {
                      "query": "From decoding to meta-generation: inference-time algorithms for large language models"
                    },
                    {
                      "query": "CMU NLP research"
                    },
                    {
                      "query": "Llm system cmu 2025"
                    },
                    {
                      "query": "Cmu 10623"
                    },
                    {
                      "query": "Sean Welleck CMU"
                    },
                    {
                      "query": "CMU LLM Certificate"
                    },
                    {
                      "query": "11767 cmu"
                    }
                  ],
                  "credits": 1
                },
                "documents": [
                  {
                    "id": "2e3c366e-1649-47bf-92d1-98831b238afa",
                    "title": "11-664/763: Inference Algorithms for Language Modeling",
                    "url": "https://www.phontron.com/class/lminference-fall2025/",
                    "snippet": "Students will understand the different ways to implement and compare inference-time techniques, learn the theory behind different strategies for inference-time ...",
                    "text": null,
                    "summary": null,
                    "score": null,
                    "error": null
                  },
                  {
                    "id": "58cd663b-df78-4cdf-bdbd-54f921d3755b",
                    "title": "CMU LLM Inference (1): Introduction to Language Models and ...",
                    "url": "https://www.youtube.com/watch?v=F-mduXzNcRQ",
                    "snippet": "This lecture (by Graham Neubig) for CMU CS 11-763, Advanced NLP (Fall 2025) covers: What is a language model? What is an inference algorithm ...",
                    "text": null,
                    "summary": null,
                    "score": null,
                    "error": null
                  }
                ],
                "query": "<query>CMU 11-763 Inference Algorithms for Language Modeling course staff instructors teaching assistants"
              },
              {
                "tool_name": "Crawl4AIBrowseTool",
                "output": "Title: 11-664/763: Inference Algorithms for Language Modeling\nURL: https://www.phontron.com/class/lminference-fall2025/\nSnippet: Students will understand the different ways to implement and compare inference-time techniques, learn the theory behind different strategies for inference-time ...\n\nTitle: CMU LLM Inference (1): Introduction to Language Models and ...\nURL: https://www.youtube.com/watch?v=F-mduXzNcRQ\nSnippet: This lecture (by Graham Neubig) for CMU CS 11-763, Advanced NLP (Fall 2025) covers: What is a language model? What is an inference algorithm ...",
                "called": true,
                "timeout": false,
                "runtime": 4.744678258895874,
                "error": "",
                "call_id": "e792ab7e",
                "raw_output": null,
                "documents": [
                  {
                    "id": "2e3c366e-1649-47bf-92d1-98831b238afa",
                    "title": "11-664/763: Inference Algorithms for Language Modeling",
                    "url": "https://www.phontron.com/class/lminference-fall2025/",
                    "snippet": "Students will understand the different ways to implement and compare inference-time techniques, learn the theory behind different strategies for inference-time ...",
                    "text": "Skip to main content Link Menu Expand (external link) Document Search Copy Copied\n11-664/763 LM Inference \n#  11-664/763: Inference Algorithms for Language Modeling\nFall 2025 @ Carnegie Mellon University\n![](https://www.phontron.com/class/lminference-fall2025/assets/images/graham_neubig.jpeg)\n###  Graham Neubig\ngneubig@cs.cmu.edu\n![](https://www.phontron.com/class/lminference-fall2025/assets/images/abertsch.jpg)\n###  Amanda Bertsch\nabertsch@cs.cmu.edu\n##  Course Description\nAs the use of massive and costly-to-train large language models has become increasingly commonplace, much academic and industry interest has focused on the methods used to generate outputs from these models \u2013 the inference process. Inference-time algorithms can be applied on top of an already-trained model to improve generation quality, lower latency, or induce additional controllability. Inference-time algorithms can allow users to run models on their laptop, serve millions of outputs at scale, or dramatically increase the quality of generations from a system without additional training.\nIn this class, we survey the wide space of inference-time techniques with a particular focus on the implementation and practical use cases of such methods. Students will understand the different ways to implement and compare inference-time techniques, learn the theory behind different strategies for inference-time scaling of compute, and implement representative examples from several classes of inference-time algorithms. In the final project, students will apply inference-time strategies of their choice to two shared tasks: an open-ended generation task and a reasoning task.\n##  Course Information\n  * **Prerequisites** : 11-411/611/711 OR 11-785 OR 10-401/601/701 OR 10-715 OR 11-667\n  * **Target Audience** : Research masters or PhD students who have some basic knowledge of language models and NLP, are comfortable with programming in Python, and are interested in understanding language model inference from an algorithmic perspective\n  * **Class Size** : Capped at 45 students\n\n\n##  Quick Links\n  * Course Details\n  * Schedule\n  * Assignments\n  * Staff\n  * Posters\n\n\n",
                    "summary": null,
                    "score": null,
                    "error": null
                  },
                  {
                    "id": "58cd663b-df78-4cdf-bdbd-54f921d3755b",
                    "title": "CMU LLM Inference (1): Introduction to Language Models and ...",
                    "url": "https://www.youtube.com/watch?v=F-mduXzNcRQ",
                    "snippet": "This lecture (by Graham Neubig) for CMU CS 11-763, Advanced NLP (Fall 2025) covers: What is a language model? What is an inference algorithm ...",
                    "text": "Back \n![](https://www.youtube.com/watch?v=F-mduXzNcRQ)\nSearch \n![](https://www.youtube.com/watch?v=F-mduXzNcRQ)\nCMU LLM Inference (1): Introduction to Language Models and Inference\nTap to unmute\n2x\nSearch\nCopy link\nInfo\nShopping\nIf playback doesn't begin shortly, try restarting your device.\n\u2022\nUp next\nLive\nUpcoming\nCancelPlay Now\nYou're signed out\nVideos you watch may be added to the TV's watch history and influence TV recommendations. To avoid this, cancel and sign in to YouTube on your computer.\nCancelConfirm\nShare\nInclude playlist\nAn error occurred while retrieving sharing information. Please try again later.\n0:00\n0:00 / 1:13:26Live\n\u2022\n\u2022\n\u2022\n#  CMU LLM Inference (1): Introduction to Language Models and Inference\n![](https://yt3.ggpht.com/ytc/AIdro_kkLmShAGppWGW_Gvvna5_rV_JjmuosUOUfqexPSyYHJg=s48-c-k-c0x00ffffff-no-rj)\nGraham Neubig\nGraham Neubig \n15.6K subscribers\nSubscribe\nSubscribed\n68\nShare\nDownload\nDownload \nSave\n1.5K views1 month ago\n1,562 views \u2022 Sep 11, 2025 \nShow less \nThis lecture (by Graham Neubig) for CMU CS 11-763, Advanced NLP (Fall 2025) covers: What is a language model?\u2026...more \n...more \nTranscript\nFollow along using the transcript.\nShow transcript\n### Graham Neubig\n15.6K subscribers \nVideos\nAbout\nVideos\nAbout\nShow less \n# CMU LLM Inference (1): Introduction to Language Models and Inference\n1,562 views1.5K views\nSep 11, 2025\n68\nShare\nDownload\nDownload \nSave\n### \n### \nNaN / NaN\n##  Comments 7\nTop comments \nNewest first \n##  Description\nCMU LLM Inference (1): Introduction to Language Models and Inference\n68Likes\n1,562Views\nSep 112025\nThis lecture (by Graham Neubig) for CMU CS 11-763, Advanced NLP (Fall 2025) covers: What is a language model? What is an inference algorithm? What will we not cover? What are transformers? How do modern LMs work? Modeling errors and search errors Class Site: https://phontron.com/class/lminferenc...\u2026...more \n...more Show less \nTranscript\nFollow along using the transcript.\nShow transcript\n### Graham Neubig\n15.6K subscribers \nVideos\nAbout\nVideos\nAbout\n##  Transcript\n![](https://i.ytimg.com/vi/UKuPCxozypU/hqdefault.jpg?sqp=-oaymwFACKgBEF5IWvKriqkDMwgBFQAAiEIYAdgBAeIBCggYEAIYBjgBQAHwAQH4Af4JgALQBYoCDAgAEAEYaSATKH8wDw==&rs=AOn4CLD4fqioQyEKQaOlv64kSvN7vdTGkw)\n1:12:06\n### CMU LLM Inference (2): Probability Review and Code Examples\nGraham Neubig\n405 views \u2022 1 month ago\n",
                    "summary": null,
                    "score": null,
                    "error": null
                  }
                ],
                "query": "<query>CMU 11-763 Inference Algorithms for Language Modeling course staff instructors teaching assistants"
              }
            ],
            "failed_at": null,
            "expected_tool_calls": 2,
            "total_tool_calls": 2,
            "total_failed_tool_calls": 0
          }
        },
        {
          "tool_name": "ChainedTool",
          "output": "Title: 11-664/763: Inference Algorithms for Language Modeling\nURL: https://www.phontron.com/class/lminference-fall2025/\nSnippet: 11-664/763: Inference Algorithms for Language Modeling. Fall 2025 @ Carnegie Mellon University. Graham Neubig \u00b7 gneubig@cs.cmu.edu \u00b7 Amanda Bertsch \u00b7 abertsch@ ...",
          "called": true,
          "timeout": false,
          "runtime": 1.9801738262176514,
          "error": "",
          "call_id": "f86c4442",
          "raw_output": {
            "tool_outputs": [
              {
                "tool_name": "SerperSearchTool",
                "output": "Title: 11-664/763: Inference Algorithms for Language Modeling\nURL: https://www.phontron.com/class/lminference-fall2025/\nSnippet: 11-664/763: Inference Algorithms for Language Modeling. Fall 2025 @ Carnegie Mellon University. Graham Neubig \u00b7 gneubig@cs.cmu.edu \u00b7 Amanda Bertsch \u00b7 abertsch@ ...",
                "called": true,
                "timeout": false,
                "runtime": 0.7753090858459473,
                "error": "",
                "call_id": "c1e80030",
                "raw_output": {
                  "searchParameters": {
                    "q": "CMU 11-763 Inference Algorithms for Language Modeling staff list site:phontron.com",
                    "gl": "us",
                    "hl": "en",
                    "type": "search",
                    "num": 2,
                    "engine": "google"
                  },
                  "organic": [
                    {
                      "title": "11-664/763: Inference Algorithms for Language Modeling",
                      "subtitle": "",
                      "link": "https://www.phontron.com/class/lminference-fall2025/",
                      "snippet": "11-664/763: Inference Algorithms for Language Modeling. Fall 2025 @ Carnegie Mellon University. Graham Neubig \u00b7 gneubig@cs.cmu.edu \u00b7 Amanda Bertsch \u00b7 abertsch@ ...",
                      "position": 1
                    }
                  ],
                  "credits": 1
                },
                "documents": [
                  {
                    "id": "f2c8570d-f860-44ce-ba98-98d6d7273b0a",
                    "title": "11-664/763: Inference Algorithms for Language Modeling",
                    "url": "https://www.phontron.com/class/lminference-fall2025/",
                    "snippet": "11-664/763: Inference Algorithms for Language Modeling. Fall 2025 @ Carnegie Mellon University. Graham Neubig \u00b7 gneubig@cs.cmu.edu \u00b7 Amanda Bertsch \u00b7 abertsch@ ...",
                    "text": null,
                    "summary": null,
                    "score": null,
                    "error": null
                  }
                ],
                "query": "CMU 11-763 Inference Algorithms for Language Modeling staff list site:phontron.com"
              },
              {
                "tool_name": "Crawl4AIBrowseTool",
                "output": "Title: 11-664/763: Inference Algorithms for Language Modeling\nURL: https://www.phontron.com/class/lminference-fall2025/\nSnippet: 11-664/763: Inference Algorithms for Language Modeling. Fall 2025 @ Carnegie Mellon University. Graham Neubig \u00b7 gneubig@cs.cmu.edu \u00b7 Amanda Bertsch \u00b7 abertsch@ ...",
                "called": true,
                "timeout": false,
                "runtime": 1.204780101776123,
                "error": "",
                "call_id": "c7cd3170",
                "raw_output": null,
                "documents": [
                  {
                    "id": "f2c8570d-f860-44ce-ba98-98d6d7273b0a",
                    "title": "11-664/763: Inference Algorithms for Language Modeling",
                    "url": "https://www.phontron.com/class/lminference-fall2025/",
                    "snippet": "11-664/763: Inference Algorithms for Language Modeling. Fall 2025 @ Carnegie Mellon University. Graham Neubig \u00b7 gneubig@cs.cmu.edu \u00b7 Amanda Bertsch \u00b7 abertsch@ ...",
                    "text": "Skip to main content Link Menu Expand (external link) Document Search Copy Copied\n11-664/763 LM Inference \n#  11-664/763: Inference Algorithms for Language Modeling\nFall 2025 @ Carnegie Mellon University\n![](https://www.phontron.com/class/lminference-fall2025/assets/images/graham_neubig.jpeg)\n###  Graham Neubig\ngneubig@cs.cmu.edu\n![](https://www.phontron.com/class/lminference-fall2025/assets/images/abertsch.jpg)\n###  Amanda Bertsch\nabertsch@cs.cmu.edu\n##  Course Description\nAs the use of massive and costly-to-train large language models has become increasingly commonplace, much academic and industry interest has focused on the methods used to generate outputs from these models \u2013 the inference process. Inference-time algorithms can be applied on top of an already-trained model to improve generation quality, lower latency, or induce additional controllability. Inference-time algorithms can allow users to run models on their laptop, serve millions of outputs at scale, or dramatically increase the quality of generations from a system without additional training.\nIn this class, we survey the wide space of inference-time techniques with a particular focus on the implementation and practical use cases of such methods. Students will understand the different ways to implement and compare inference-time techniques, learn the theory behind different strategies for inference-time scaling of compute, and implement representative examples from several classes of inference-time algorithms. In the final project, students will apply inference-time strategies of their choice to two shared tasks: an open-ended generation task and a reasoning task.\n##  Course Information\n  * **Prerequisites** : 11-411/611/711 OR 11-785 OR 10-401/601/701 OR 10-715 OR 11-667\n  * **Target Audience** : Research masters or PhD students who have some basic knowledge of language models and NLP, are comfortable with programming in Python, and are interested in understanding language model inference from an algorithmic perspective\n  * **Class Size** : Capped at 45 students\n\n\n##  Quick Links\n  * Course Details\n  * Schedule\n  * Assignments\n  * Staff\n  * Posters\n\n\n",
                    "summary": null,
                    "score": null,
                    "error": null
                  }
                ],
                "query": "CMU 11-763 Inference Algorithms for Language Modeling staff list site:phontron.com"
              }
            ],
            "failed_at": null,
            "expected_tool_calls": 2,
            "total_tool_calls": 2,
            "total_failed_tool_calls": 0
          }
        },
        {
          "tool_name": "ChainedTool",
          "output": "Title: 11-664/763: Inference Algorithms for Language Modeling\nURL: https://www.phontron.com/class/lminference-fall2025/\nSnippet: A class at Carnegie Mellon University on language model inference algorithms ... Graham Neubig \u00b7 gneubig@cs.cmu.edu \u00b7 Amanda Bertsch \u00b7 abertsch@cs.cmu.edu. Course ...\n\nTitle: Learn Inference Algorithms for Language Modeling at CMU - LinkedIn\nURL: https://www.linkedin.com/posts/kelvinmeeks_11-663763-lm-inference-activity-7341239778308214786-5NXw\nSnippet: ... Carnegie Mellon University Taught by Graham Neubig, and Amanda Bertsch \"Inference-time algorithms can allow users to run models on their ...",
          "called": true,
          "timeout": false,
          "runtime": 2.409590244293213,
          "error": "",
          "call_id": "be20b276",
          "raw_output": {
            "tool_outputs": [
              {
                "tool_name": "SerperSearchTool",
                "output": "Title: 11-664/763: Inference Algorithms for Language Modeling\nURL: https://www.phontron.com/class/lminference-fall2025/\nSnippet: A class at Carnegie Mellon University on language model inference algorithms ... Graham Neubig \u00b7 gneubig@cs.cmu.edu \u00b7 Amanda Bertsch \u00b7 abertsch@cs.cmu.edu. Course ...\n\nTitle: Learn Inference Algorithms for Language Modeling at CMU - LinkedIn\nURL: https://www.linkedin.com/posts/kelvinmeeks_11-663763-lm-inference-activity-7341239778308214786-5NXw\nSnippet: ... Carnegie Mellon University Taught by Graham Neubig, and Amanda Bertsch \"Inference-time algorithms can allow users to run models on their ...",
                "called": true,
                "timeout": false,
                "runtime": 0.7991962432861328,
                "error": "",
                "call_id": "3cc4accc",
                "raw_output": {
                  "searchParameters": {
                    "q": "CMU 11-763 Inference Algorithms for Language Modeling staff members Graham Neubig Amanda Bertsch",
                    "gl": "us",
                    "hl": "en",
                    "type": "search",
                    "num": 2,
                    "engine": "google"
                  },
                  "organic": [
                    {
                      "title": "11-664/763: Inference Algorithms for Language Modeling",
                      "link": "https://www.phontron.com/class/lminference-fall2025/",
                      "snippet": "A class at Carnegie Mellon University on language model inference algorithms ... Graham Neubig \u00b7 gneubig@cs.cmu.edu \u00b7 Amanda Bertsch \u00b7 abertsch@cs.cmu.edu. Course ...",
                      "attributes": {
                        "Missing": "members | Show results with:members"
                      },
                      "position": 1
                    },
                    {
                      "title": "Learn Inference Algorithms for Language Modeling at CMU - LinkedIn",
                      "link": "https://www.linkedin.com/posts/kelvinmeeks_11-663763-lm-inference-activity-7341239778308214786-5NXw",
                      "snippet": "... Carnegie Mellon University Taught by Graham Neubig, and Amanda Bertsch \"Inference-time algorithms can allow users to run models on their ...",
                      "date": "Jun 18, 2025",
                      "attributes": {
                        "Missing": "staff | Show results with:staff"
                      },
                      "position": 2
                    }
                  ],
                  "credits": 1
                },
                "documents": [
                  {
                    "id": "264613b4-830e-421e-a021-921e85e8b29d",
                    "title": "11-664/763: Inference Algorithms for Language Modeling",
                    "url": "https://www.phontron.com/class/lminference-fall2025/",
                    "snippet": "A class at Carnegie Mellon University on language model inference algorithms ... Graham Neubig \u00b7 gneubig@cs.cmu.edu \u00b7 Amanda Bertsch \u00b7 abertsch@cs.cmu.edu. Course ...",
                    "text": null,
                    "summary": null,
                    "score": null,
                    "error": null
                  },
                  {
                    "id": "b0cba5df-7497-4f4b-ac71-94041f6b4b32",
                    "title": "Learn Inference Algorithms for Language Modeling at CMU - LinkedIn",
                    "url": "https://www.linkedin.com/posts/kelvinmeeks_11-663763-lm-inference-activity-7341239778308214786-5NXw",
                    "snippet": "... Carnegie Mellon University Taught by Graham Neubig, and Amanda Bertsch \"Inference-time algorithms can allow users to run models on their ...",
                    "text": null,
                    "summary": null,
                    "score": null,
                    "error": null
                  }
                ],
                "query": "CMU 11-763 Inference Algorithms for Language Modeling staff members Graham Neubig Amanda Bertsch"
              },
              {
                "tool_name": "Crawl4AIBrowseTool",
                "output": "Title: 11-664/763: Inference Algorithms for Language Modeling\nURL: https://www.phontron.com/class/lminference-fall2025/\nSnippet: A class at Carnegie Mellon University on language model inference algorithms ... Graham Neubig \u00b7 gneubig@cs.cmu.edu \u00b7 Amanda Bertsch \u00b7 abertsch@cs.cmu.edu. Course ...\n\nTitle: Learn Inference Algorithms for Language Modeling at CMU - LinkedIn\nURL: https://www.linkedin.com/posts/kelvinmeeks_11-663763-lm-inference-activity-7341239778308214786-5NXw\nSnippet: ... Carnegie Mellon University Taught by Graham Neubig, and Amanda Bertsch \"Inference-time algorithms can allow users to run models on their ...",
                "called": true,
                "timeout": false,
                "runtime": 1.6103448867797852,
                "error": "",
                "call_id": "a8c56e1f",
                "raw_output": null,
                "documents": [
                  {
                    "id": "264613b4-830e-421e-a021-921e85e8b29d",
                    "title": "11-664/763: Inference Algorithms for Language Modeling",
                    "url": "https://www.phontron.com/class/lminference-fall2025/",
                    "snippet": "A class at Carnegie Mellon University on language model inference algorithms ... Graham Neubig \u00b7 gneubig@cs.cmu.edu \u00b7 Amanda Bertsch \u00b7 abertsch@cs.cmu.edu. Course ...",
                    "text": "Skip to main content Link Menu Expand (external link) Document Search Copy Copied\n11-664/763 LM Inference \n#  11-664/763: Inference Algorithms for Language Modeling\nFall 2025 @ Carnegie Mellon University\n![](https://www.phontron.com/class/lminference-fall2025/assets/images/graham_neubig.jpeg)\n###  Graham Neubig\ngneubig@cs.cmu.edu\n![](https://www.phontron.com/class/lminference-fall2025/assets/images/abertsch.jpg)\n###  Amanda Bertsch\nabertsch@cs.cmu.edu\n##  Course Description\nAs the use of massive and costly-to-train large language models has become increasingly commonplace, much academic and industry interest has focused on the methods used to generate outputs from these models \u2013 the inference process. Inference-time algorithms can be applied on top of an already-trained model to improve generation quality, lower latency, or induce additional controllability. Inference-time algorithms can allow users to run models on their laptop, serve millions of outputs at scale, or dramatically increase the quality of generations from a system without additional training.\nIn this class, we survey the wide space of inference-time techniques with a particular focus on the implementation and practical use cases of such methods. Students will understand the different ways to implement and compare inference-time techniques, learn the theory behind different strategies for inference-time scaling of compute, and implement representative examples from several classes of inference-time algorithms. In the final project, students will apply inference-time strategies of their choice to two shared tasks: an open-ended generation task and a reasoning task.\n##  Course Information\n  * **Prerequisites** : 11-411/611/711 OR 11-785 OR 10-401/601/701 OR 10-715 OR 11-667\n  * **Target Audience** : Research masters or PhD students who have some basic knowledge of language models and NLP, are comfortable with programming in Python, and are interested in understanding language model inference from an algorithmic perspective\n  * **Class Size** : Capped at 45 students\n\n\n##  Quick Links\n  * Course Details\n  * Schedule\n  * Assignments\n  * Staff\n  * Posters\n\n\n",
                    "summary": null,
                    "score": null,
                    "error": null
                  },
                  {
                    "id": "b0cba5df-7497-4f4b-ac71-94041f6b4b32",
                    "title": "Learn Inference Algorithms for Language Modeling at CMU - LinkedIn",
                    "url": "https://www.linkedin.com/posts/kelvinmeeks_11-663763-lm-inference-activity-7341239778308214786-5NXw",
                    "snippet": "... Carnegie Mellon University Taught by Graham Neubig, and Amanda Bertsch \"Inference-time algorithms can allow users to run models on their ...",
                    "text": "`` `` `` `` `` `` Skip to main content \n#  Learn Inference Algorithms for Language Modeling at CMU\nThis title was summarized by AI from the post below.\nKelvin Meeks \nConsulting Architect/CTO - Leadership in Enterprise Architecture and Software Engineering Innovation (US Army Veteran) \n4mo  Edited \n  * \n\nNoteworthy: 11-663/763: Inference Algorithms for Language Modeling Fall 2025 Carnegie Mellon University Taught by Graham Neubig, and Amanda Bertsch \"Inference-time algorithms can allow users to run models on their laptop, serve millions of outputs at scale, or dramatically increase the quality of generations from a system without additional training.\" \"In this class, we survey the wide space of inference-time techniques with a particular focus on the implementation and practical use cases of such methods. Students will understand the different ways to implement and compare inference-time techniques, learn the theory behind different strategies for inference-time scaling of compute, and implement representative examples from several classes of inference-time algorithms. In the final project, students will apply inference-time strategies of their choice to two shared tasks: an open-ended generation task and a reasoning task.\" https://lnkd.in/gtn2rrsc\n`` ``\nLike  Comment  `` ``\nShare \n  * Copy\n  * LinkedIn\n  * Facebook\n  * X\n\n\nTo view or add a comment, sign in\n``\n![](https://media.licdn.com/dms/image/v2/D5616AQEEuon8PR5GEA/profile-displaybackgroundimage-shrink_200_800/B56Zn.gfFqI4AU-/0/1760911553925?e=2147483647&v=beta&t=k9SuklukXirkp3DRDZIxpyjPuzAcPkjFVtYTDSgsK9I)\n6,557 followers \n  * 2,880 Posts \n  * 20 Articles \n\n\nView Profile  Connect\n##  More from this author \n  * ###  Trusting Your Intuition - Though You May Stand Alone \nKelvin Meeks  3y \n  * ###  Why Your Pitch Failed \nKelvin Meeks  4y \n  * ###  Remember, There Is No Free Lunch \nKelvin Meeks  5y \n\n\n##  Explore content categories \n  * Career\n  * Productivity\n  * Finance\n  * Soft Skills & Emotional Intelligence\n  * Project Management\n  * Education\n  * Technology\n  * Leadership\n  * Ecommerce\n  * User Experience\n\nShow more  Show less \n##  Sign in to view more content \nCreate your free account or sign in to continue your search \nSign in \n##  Welcome back \n`` `` `` `` `` `` `` `` `` ``\nBy clicking Continue to join or sign in, you agree to LinkedIn\u2019s User Agreement, Privacy Policy, and Cookie Policy. \nNew to LinkedIn? Join now\nor \nNew to LinkedIn? Join now\nBy clicking Continue to join or sign in, you agree to LinkedIn\u2019s User Agreement, Privacy Policy, and Cookie Policy. \n``\n",
                    "summary": null,
                    "score": null,
                    "error": null
                  }
                ],
                "query": "CMU 11-763 Inference Algorithms for Language Modeling staff members Graham Neubig Amanda Bertsch"
              }
            ],
            "failed_at": null,
            "expected_tool_calls": 2,
            "total_tool_calls": 2,
            "total_failed_tool_calls": 0
          }
        },
        {
          "tool_name": "ChainedTool",
          "output": "Title: 11-664/763: Inference Algorithms for Language Modeling\nURL: https://www.phontron.com/class/lminference-fall2025/\nSnippet: Graham Neubig \u00b7 gneubig@cs.cmu.edu \u00b7 Amanda Bertsch \u00b7 abertsch@cs.cmu.edu. Course ... classes of inference-time algorithms. In the final project, students ...\n\nTitle: Amanda Bertsch - CMU School of Computer Science\nURL: https://www.cs.cmu.edu/~abertsch/\nSnippet: I am a PhD student in the Language Technologies Institute at Carnegie Mellon University, advised by Matt Gormley and Graham Neubig.",
          "called": true,
          "timeout": false,
          "runtime": 2.899113893508911,
          "error": "",
          "call_id": "1303dd4c",
          "raw_output": {
            "tool_outputs": [
              {
                "tool_name": "SerperSearchTool",
                "output": "Title: 11-664/763: Inference Algorithms for Language Modeling\nURL: https://www.phontron.com/class/lminference-fall2025/\nSnippet: Graham Neubig \u00b7 gneubig@cs.cmu.edu \u00b7 Amanda Bertsch \u00b7 abertsch@cs.cmu.edu. Course ... classes of inference-time algorithms. In the final project, students ...\n\nTitle: Amanda Bertsch - CMU School of Computer Science\nURL: https://www.cs.cmu.edu/~abertsch/\nSnippet: I am a PhD student in the Language Technologies Institute at Carnegie Mellon University, advised by Matt Gormley and Graham Neubig.",
                "called": true,
                "timeout": false,
                "runtime": 0.9244899749755859,
                "error": "",
                "call_id": "b5eec48e",
                "raw_output": {
                  "searchParameters": {
                    "q": "CMU 11-763 Inference Algorithms for Language Modeling instructors Graham Neubig Amanda Bertsch contact",
                    "gl": "us",
                    "hl": "en",
                    "type": "search",
                    "num": 2,
                    "engine": "google"
                  },
                  "organic": [
                    {
                      "title": "11-664/763: Inference Algorithms for Language Modeling",
                      "link": "https://www.phontron.com/class/lminference-fall2025/",
                      "snippet": "Graham Neubig \u00b7 gneubig@cs.cmu.edu \u00b7 Amanda Bertsch \u00b7 abertsch@cs.cmu.edu. Course ... classes of inference-time algorithms. In the final project, students ...",
                      "attributes": {
                        "Missing": "instructors | Show results with:instructors"
                      },
                      "position": 1
                    },
                    {
                      "title": "Amanda Bertsch - CMU School of Computer Science",
                      "link": "https://www.cs.cmu.edu/~abertsch/",
                      "snippet": "I am a PhD student in the Language Technologies Institute at Carnegie Mellon University, advised by Matt Gormley and Graham Neubig.",
                      "attributes": {
                        "Missing": "11-763 instructors"
                      },
                      "position": 2
                    }
                  ],
                  "credits": 1
                },
                "documents": [
                  {
                    "id": "b492beb6-4fdc-4644-ad93-5d7f46115493",
                    "title": "11-664/763: Inference Algorithms for Language Modeling",
                    "url": "https://www.phontron.com/class/lminference-fall2025/",
                    "snippet": "Graham Neubig \u00b7 gneubig@cs.cmu.edu \u00b7 Amanda Bertsch \u00b7 abertsch@cs.cmu.edu. Course ... classes of inference-time algorithms. In the final project, students ...",
                    "text": null,
                    "summary": null,
                    "score": null,
                    "error": null
                  },
                  {
                    "id": "f0beda82-dcab-40d4-8c07-a3ec5899316e",
                    "title": "Amanda Bertsch - CMU School of Computer Science",
                    "url": "https://www.cs.cmu.edu/~abertsch/",
                    "snippet": "I am a PhD student in the Language Technologies Institute at Carnegie Mellon University, advised by Matt Gormley and Graham Neubig.",
                    "text": null,
                    "summary": null,
                    "score": null,
                    "error": null
                  }
                ],
                "query": "CMU 11-763 Inference Algorithms for Language Modeling instructors Graham Neubig Amanda Bertsch contact"
              },
              {
                "tool_name": "Crawl4AIBrowseTool",
                "output": "Title: 11-664/763: Inference Algorithms for Language Modeling\nURL: https://www.phontron.com/class/lminference-fall2025/\nSnippet: Graham Neubig \u00b7 gneubig@cs.cmu.edu \u00b7 Amanda Bertsch \u00b7 abertsch@cs.cmu.edu. Course ... classes of inference-time algorithms. In the final project, students ...\n\nTitle: Amanda Bertsch - CMU School of Computer Science\nURL: https://www.cs.cmu.edu/~abertsch/\nSnippet: I am a PhD student in the Language Technologies Institute at Carnegie Mellon University, advised by Matt Gormley and Graham Neubig.",
                "called": true,
                "timeout": false,
                "runtime": 1.9745631217956543,
                "error": "",
                "call_id": "10645fde",
                "raw_output": null,
                "documents": [
                  {
                    "id": "b492beb6-4fdc-4644-ad93-5d7f46115493",
                    "title": "11-664/763: Inference Algorithms for Language Modeling",
                    "url": "https://www.phontron.com/class/lminference-fall2025/",
                    "snippet": "Graham Neubig \u00b7 gneubig@cs.cmu.edu \u00b7 Amanda Bertsch \u00b7 abertsch@cs.cmu.edu. Course ... classes of inference-time algorithms. In the final project, students ...",
                    "text": "Skip to main content Link Menu Expand (external link) Document Search Copy Copied\n11-664/763 LM Inference \n#  11-664/763: Inference Algorithms for Language Modeling\nFall 2025 @ Carnegie Mellon University\n![](https://www.phontron.com/class/lminference-fall2025/assets/images/graham_neubig.jpeg)\n###  Graham Neubig\ngneubig@cs.cmu.edu\n![](https://www.phontron.com/class/lminference-fall2025/assets/images/abertsch.jpg)\n###  Amanda Bertsch\nabertsch@cs.cmu.edu\n##  Course Description\nAs the use of massive and costly-to-train large language models has become increasingly commonplace, much academic and industry interest has focused on the methods used to generate outputs from these models \u2013 the inference process. Inference-time algorithms can be applied on top of an already-trained model to improve generation quality, lower latency, or induce additional controllability. Inference-time algorithms can allow users to run models on their laptop, serve millions of outputs at scale, or dramatically increase the quality of generations from a system without additional training.\nIn this class, we survey the wide space of inference-time techniques with a particular focus on the implementation and practical use cases of such methods. Students will understand the different ways to implement and compare inference-time techniques, learn the theory behind different strategies for inference-time scaling of compute, and implement representative examples from several classes of inference-time algorithms. In the final project, students will apply inference-time strategies of their choice to two shared tasks: an open-ended generation task and a reasoning task.\n##  Course Information\n  * **Prerequisites** : 11-411/611/711 OR 11-785 OR 10-401/601/701 OR 10-715 OR 11-667\n  * **Target Audience** : Research masters or PhD students who have some basic knowledge of language models and NLP, are comfortable with programming in Python, and are interested in understanding language model inference from an algorithmic perspective\n  * **Class Size** : Capped at 45 students\n\n\n##  Quick Links\n  * Course Details\n  * Schedule\n  * Assignments\n  * Staff\n  * Posters\n\n\n",
                    "summary": null,
                    "score": null,
                    "error": null
                  },
                  {
                    "id": "f0beda82-dcab-40d4-8c07-a3ec5899316e",
                    "title": "Amanda Bertsch - CMU School of Computer Science",
                    "url": "https://www.cs.cmu.edu/~abertsch/",
                    "snippet": "I am a PhD student in the Language Technologies Institute at Carnegie Mellon University, advised by Matt Gormley and Graham Neubig.",
                    "text": "![profile.jpg](https://www.cs.cmu.edu/~abertsch/assets/img/profile.jpg?534245c3dc2b04a94165673d90126030)\nI am a PhD student in the Language Technologies Institute at Carnegie Mellon University, advised by Matt Gormley and Graham Neubig. I am a member of NeuLab and an organizer for Queer in AI. I\u2019m fortunate to be funded by an NSF Graduate Research Fellowship.\nI work primarily on conditional generation, particularly long-context modeling and inference-time algorithms; my broader research interests include better ways to reason over large quantities of knowledge, model large-scale structure in text, and effectively integrate external knowledge into models. Currently, I\u2019m excited about evaluation for realistic long-context settings, more efficient model deployment, and understanding how community divergence affects whose work we engage with. I\u2019m also broadly interested in meta-analysis of the NLP community, including critically examining the benchmarks, datasets, and modeling choices we take as defaults.\nI\u2019m trying to get to know my academic neighbors! If we work on similar things (or very different things that might be connected in interesting ways), I\u2019d love to chat\u2013 please email me :)\nBefore coming to CMU, I received my bachelors in math and computer science from the University of Arizona, where I was advised by Steven Bethard. Before coming to NLP, I worked in soil microbiology, built large-scale Rube Goldberg machines, and occasionally published short fiction. In my spare time, I write and read speculative fiction, hike, run, and play tabletop games.\n##  news\nMar 10, 2025 |  I\u2019ll be presenting our work on long-context in-context learning at NAACL in Albuquerque!   \n---|---  \nFeb 15, 2025 |  And this summer (summer 2025), I\u2019ll be back in Seattle, interning with Dirk Groeneveld at AI2 and working on OLMo!   \nMay 15, 2024 |  I\u2019m interning this summer with Mike Lewis at Meta GenAI! Excited to spend the summer thinking about long context & hiking in Seattle :)   \nOct 24, 2023 |  Excited to announce some new work going to EMNLP: a qualitative study of the NLP community (main); a system for distilling a model from a single textual instruction (demo); and an analysis paper about Minimum Bayes Risk decoding, (Big Picture workshop)! Looking forward to seeing folks in Singapore.   \nJun 06, 2023 |  Check out our recent preprints: Unlimiformer, a long-range transformer and a survey on human feedback for generation! (Update September 2023: Unlimiformer was accepted to NeurIPS, and this survey was accepted to TACL!)   \n##  selected publications\n  1. preprint\nEfficient Many-Shot In-Context Learning with Dynamic Block-Sparse Attention\nEmily Xiao, Chin-Jou Li, Yilin Zhang, Graham Neubig, and  _Amanda Bertsch_\n_In [under submission]_ , 2025 \nPDF\n  2. NAACL\nIn-context learning with long-context models: An in-depth exploration\n_Amanda Bertsch_ , Maor Ivgi, Uri Alon, Jonathan Berant, Matthew R Gormley, and Graham Neubig \n_In 2025 Annual Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics_ , 2025 \nPDF\n  3. TMLR\nFrom Decoding to Meta-Generation: Inference-time Algorithms for Large Language Models\nSean Welleck,  _Amanda Bertsch_ , Matthew Finlayson, Hailey Schoelkopf, Alex Xie, Graham Neubig, and 2 more authors\n_In Transactions on Machine Learning Research_ , 2024 \nPDF\n  4. EMNLP\nTo Build Our Future, We Must Know Our Past: Contextualizing Paradigm Shifts in Natural Language Processing\nSireesh Gururaja,  _Amanda Bertsch_ , Clara Na, David Gray Widder, and Emma Strubell \n_In Empirical Methods in Natural Language Processing._ , 2023 \nPDF\n  5. NeurIPS\nUnlimiformer: Long-Range Transformers with Unlimited Length Input\n_Amanda Bertsch_ , Uri Alon, Graham Neubig, and Matthew R. Gormley \n_In Conference on Neural Information Processing Systems._ , 2023 \nPDF\n\n\nEmail or openNLP slack preferred! \n",
                    "summary": null,
                    "score": null,
                    "error": null
                  }
                ],
                "query": "CMU 11-763 Inference Algorithms for Language Modeling instructors Graham Neubig Amanda Bertsch contact"
              }
            ],
            "failed_at": null,
            "expected_tool_calls": 2,
            "total_tool_calls": 2,
            "total_failed_tool_calls": 0
          }
        },
        {
          "tool_name": "ChainedTool",
          "output": "Title: 11-664/763: Inference Algorithms for Language Modeling\nURL: https://www.phontron.com/class/lminference-fall2025/\nSnippet: A class at Carnegie Mellon University on language model inference algorithms ... Graham Neubig \u00b7 gneubig@cs.cmu.edu \u00b7 Amanda Bertsch \u00b7 abertsch@cs.cmu.edu ...\n\nTitle: Amanda Bertsch - CMU School of Computer Science\nURL: https://www.cs.cmu.edu/~abertsch/\nSnippet: I am a PhD student in the Language Technologies Institute at Carnegie Mellon University, advised by Matt Gormley and Graham Neubig.",
          "called": true,
          "timeout": false,
          "runtime": 5.0426857471466064,
          "error": "",
          "call_id": "4ee09327",
          "raw_output": {
            "tool_outputs": [
              {
                "tool_name": "SerperSearchTool",
                "output": "Title: 11-664/763: Inference Algorithms for Language Modeling\nURL: https://www.phontron.com/class/lminference-fall2025/\nSnippet: A class at Carnegie Mellon University on language model inference algorithms ... Graham Neubig \u00b7 gneubig@cs.cmu.edu \u00b7 Amanda Bertsch \u00b7 abertsch@cs.cmu.edu ...\n\nTitle: Amanda Bertsch - CMU School of Computer Science\nURL: https://www.cs.cmu.edu/~abertsch/\nSnippet: I am a PhD student in the Language Technologies Institute at Carnegie Mellon University, advised by Matt Gormley and Graham Neubig.",
                "called": true,
                "timeout": false,
                "runtime": 3.180663824081421,
                "error": "",
                "call_id": "43750907",
                "raw_output": {
                  "searchParameters": {
                    "q": "CMU 11-763 Inference Algorithms for Language Modeling course staff Graham Neubig Amanda Bertsch email",
                    "gl": "us",
                    "hl": "en",
                    "type": "search",
                    "num": 2,
                    "engine": "google"
                  },
                  "organic": [
                    {
                      "title": "11-664/763: Inference Algorithms for Language Modeling",
                      "link": "https://www.phontron.com/class/lminference-fall2025/",
                      "snippet": "A class at Carnegie Mellon University on language model inference algorithms ... Graham Neubig \u00b7 gneubig@cs.cmu.edu \u00b7 Amanda Bertsch \u00b7 abertsch@cs.cmu.edu ...",
                      "attributes": {
                        "Missing": "email | Show results with:email"
                      },
                      "position": 1
                    },
                    {
                      "title": "Amanda Bertsch - CMU School of Computer Science",
                      "link": "https://www.cs.cmu.edu/~abertsch/",
                      "snippet": "I am a PhD student in the Language Technologies Institute at Carnegie Mellon University, advised by Matt Gormley and Graham Neubig.",
                      "attributes": {
                        "Missing": "11-763 course staff"
                      },
                      "position": 2
                    }
                  ],
                  "credits": 1
                },
                "documents": [
                  {
                    "id": "10dc79b2-2902-48fa-a9a3-b66d7c95f490",
                    "title": "11-664/763: Inference Algorithms for Language Modeling",
                    "url": "https://www.phontron.com/class/lminference-fall2025/",
                    "snippet": "A class at Carnegie Mellon University on language model inference algorithms ... Graham Neubig \u00b7 gneubig@cs.cmu.edu \u00b7 Amanda Bertsch \u00b7 abertsch@cs.cmu.edu ...",
                    "text": null,
                    "summary": null,
                    "score": null,
                    "error": null
                  },
                  {
                    "id": "949f9079-30ca-4937-aaeb-02add5b36e85",
                    "title": "Amanda Bertsch - CMU School of Computer Science",
                    "url": "https://www.cs.cmu.edu/~abertsch/",
                    "snippet": "I am a PhD student in the Language Technologies Institute at Carnegie Mellon University, advised by Matt Gormley and Graham Neubig.",
                    "text": null,
                    "summary": null,
                    "score": null,
                    "error": null
                  }
                ],
                "query": "CMU 11-763 Inference Algorithms for Language Modeling course staff Graham Neubig Amanda Bertsch email"
              },
              {
                "tool_name": "Crawl4AIBrowseTool",
                "output": "Title: 11-664/763: Inference Algorithms for Language Modeling\nURL: https://www.phontron.com/class/lminference-fall2025/\nSnippet: A class at Carnegie Mellon University on language model inference algorithms ... Graham Neubig \u00b7 gneubig@cs.cmu.edu \u00b7 Amanda Bertsch \u00b7 abertsch@cs.cmu.edu ...\n\nTitle: Amanda Bertsch - CMU School of Computer Science\nURL: https://www.cs.cmu.edu/~abertsch/\nSnippet: I am a PhD student in the Language Technologies Institute at Carnegie Mellon University, advised by Matt Gormley and Graham Neubig.",
                "called": true,
                "timeout": false,
                "runtime": 1.8619091510772705,
                "error": "",
                "call_id": "e52feca1",
                "raw_output": null,
                "documents": [
                  {
                    "id": "10dc79b2-2902-48fa-a9a3-b66d7c95f490",
                    "title": "11-664/763: Inference Algorithms for Language Modeling",
                    "url": "https://www.phontron.com/class/lminference-fall2025/",
                    "snippet": "A class at Carnegie Mellon University on language model inference algorithms ... Graham Neubig \u00b7 gneubig@cs.cmu.edu \u00b7 Amanda Bertsch \u00b7 abertsch@cs.cmu.edu ...",
                    "text": "Skip to main content Link Menu Expand (external link) Document Search Copy Copied\n11-664/763 LM Inference \n#  11-664/763: Inference Algorithms for Language Modeling\nFall 2025 @ Carnegie Mellon University\n![](https://www.phontron.com/class/lminference-fall2025/assets/images/graham_neubig.jpeg)\n###  Graham Neubig\ngneubig@cs.cmu.edu\n![](https://www.phontron.com/class/lminference-fall2025/assets/images/abertsch.jpg)\n###  Amanda Bertsch\nabertsch@cs.cmu.edu\n##  Course Description\nAs the use of massive and costly-to-train large language models has become increasingly commonplace, much academic and industry interest has focused on the methods used to generate outputs from these models \u2013 the inference process. Inference-time algorithms can be applied on top of an already-trained model to improve generation quality, lower latency, or induce additional controllability. Inference-time algorithms can allow users to run models on their laptop, serve millions of outputs at scale, or dramatically increase the quality of generations from a system without additional training.\nIn this class, we survey the wide space of inference-time techniques with a particular focus on the implementation and practical use cases of such methods. Students will understand the different ways to implement and compare inference-time techniques, learn the theory behind different strategies for inference-time scaling of compute, and implement representative examples from several classes of inference-time algorithms. In the final project, students will apply inference-time strategies of their choice to two shared tasks: an open-ended generation task and a reasoning task.\n##  Course Information\n  * **Prerequisites** : 11-411/611/711 OR 11-785 OR 10-401/601/701 OR 10-715 OR 11-667\n  * **Target Audience** : Research masters or PhD students who have some basic knowledge of language models and NLP, are comfortable with programming in Python, and are interested in understanding language model inference from an algorithmic perspective\n  * **Class Size** : Capped at 45 students\n\n\n##  Quick Links\n  * Course Details\n  * Schedule\n  * Assignments\n  * Staff\n  * Posters\n\n\n",
                    "summary": null,
                    "score": null,
                    "error": null
                  },
                  {
                    "id": "949f9079-30ca-4937-aaeb-02add5b36e85",
                    "title": "Amanda Bertsch - CMU School of Computer Science",
                    "url": "https://www.cs.cmu.edu/~abertsch/",
                    "snippet": "I am a PhD student in the Language Technologies Institute at Carnegie Mellon University, advised by Matt Gormley and Graham Neubig.",
                    "text": "![profile.jpg](https://www.cs.cmu.edu/~abertsch/assets/img/profile.jpg?534245c3dc2b04a94165673d90126030)\nI am a PhD student in the Language Technologies Institute at Carnegie Mellon University, advised by Matt Gormley and Graham Neubig. I am a member of NeuLab and an organizer for Queer in AI. I\u2019m fortunate to be funded by an NSF Graduate Research Fellowship.\nI work primarily on conditional generation, particularly long-context modeling and inference-time algorithms; my broader research interests include better ways to reason over large quantities of knowledge, model large-scale structure in text, and effectively integrate external knowledge into models. Currently, I\u2019m excited about evaluation for realistic long-context settings, more efficient model deployment, and understanding how community divergence affects whose work we engage with. I\u2019m also broadly interested in meta-analysis of the NLP community, including critically examining the benchmarks, datasets, and modeling choices we take as defaults.\nI\u2019m trying to get to know my academic neighbors! If we work on similar things (or very different things that might be connected in interesting ways), I\u2019d love to chat\u2013 please email me :)\nBefore coming to CMU, I received my bachelors in math and computer science from the University of Arizona, where I was advised by Steven Bethard. Before coming to NLP, I worked in soil microbiology, built large-scale Rube Goldberg machines, and occasionally published short fiction. In my spare time, I write and read speculative fiction, hike, run, and play tabletop games.\n##  news\nMar 10, 2025 |  I\u2019ll be presenting our work on long-context in-context learning at NAACL in Albuquerque!   \n---|---  \nFeb 15, 2025 |  And this summer (summer 2025), I\u2019ll be back in Seattle, interning with Dirk Groeneveld at AI2 and working on OLMo!   \nMay 15, 2024 |  I\u2019m interning this summer with Mike Lewis at Meta GenAI! Excited to spend the summer thinking about long context & hiking in Seattle :)   \nOct 24, 2023 |  Excited to announce some new work going to EMNLP: a qualitative study of the NLP community (main); a system for distilling a model from a single textual instruction (demo); and an analysis paper about Minimum Bayes Risk decoding, (Big Picture workshop)! Looking forward to seeing folks in Singapore.   \nJun 06, 2023 |  Check out our recent preprints: Unlimiformer, a long-range transformer and a survey on human feedback for generation! (Update September 2023: Unlimiformer was accepted to NeurIPS, and this survey was accepted to TACL!)   \n##  selected publications\n  1. preprint\nEfficient Many-Shot In-Context Learning with Dynamic Block-Sparse Attention\nEmily Xiao, Chin-Jou Li, Yilin Zhang, Graham Neubig, and  _Amanda Bertsch_\n_In [under submission]_ , 2025 \nPDF\n  2. NAACL\nIn-context learning with long-context models: An in-depth exploration\n_Amanda Bertsch_ , Maor Ivgi, Uri Alon, Jonathan Berant, Matthew R Gormley, and Graham Neubig \n_In 2025 Annual Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics_ , 2025 \nPDF\n  3. TMLR\nFrom Decoding to Meta-Generation: Inference-time Algorithms for Large Language Models\nSean Welleck,  _Amanda Bertsch_ , Matthew Finlayson, Hailey Schoelkopf, Alex Xie, Graham Neubig, and 2 more authors\n_In Transactions on Machine Learning Research_ , 2024 \nPDF\n  4. EMNLP\nTo Build Our Future, We Must Know Our Past: Contextualizing Paradigm Shifts in Natural Language Processing\nSireesh Gururaja,  _Amanda Bertsch_ , Clara Na, David Gray Widder, and Emma Strubell \n_In Empirical Methods in Natural Language Processing._ , 2023 \nPDF\n  5. NeurIPS\nUnlimiformer: Long-Range Transformers with Unlimited Length Input\n_Amanda Bertsch_ , Uri Alon, Graham Neubig, and Matthew R. Gormley \n_In Conference on Neural Information Processing Systems._ , 2023 \nPDF\n\n\nEmail or openNLP slack preferred! \n",
                    "summary": null,
                    "score": null,
                    "error": null
                  }
                ],
                "query": "CMU 11-763 Inference Algorithms for Language Modeling course staff Graham Neubig Amanda Bertsch email"
              }
            ],
            "failed_at": null,
            "expected_tool_calls": 2,
            "total_tool_calls": 2,
            "total_failed_tool_calls": 0
          }
        },
        {
          "tool_name": "ChainedTool",
          "output": "Title: 11-664/763: Inference Algorithms for Language Modeling\nURL: https://www.phontron.com/class/lminference-fall2025/\nSnippet: Graham Neubig \u00b7 gneubig@cs.cmu.edu \u00b7 Amanda Bertsch \u00b7 abertsch@cs.cmu.edu. Course ... Course Information. Prerequisites: 11-411/611/711 OR 11-785 OR 10-401/601 ...\n\nTitle: Amanda Bertsch - CMU School of Computer Science\nURL: https://www.cs.cmu.edu/~abertsch/\nSnippet: I am a PhD student in the Language Technologies Institute at Carnegie Mellon University, advised by Matt Gormley and Graham Neubig.",
          "called": true,
          "timeout": false,
          "runtime": 3.283024311065674,
          "error": "",
          "call_id": "ef07d6da",
          "raw_output": {
            "tool_outputs": [
              {
                "tool_name": "SerperSearchTool",
                "output": "Title: 11-664/763: Inference Algorithms for Language Modeling\nURL: https://www.phontron.com/class/lminference-fall2025/\nSnippet: Graham Neubig \u00b7 gneubig@cs.cmu.edu \u00b7 Amanda Bertsch \u00b7 abertsch@cs.cmu.edu. Course ... Course Information. Prerequisites: 11-411/611/711 OR 11-785 OR 10-401/601 ...\n\nTitle: Amanda Bertsch - CMU School of Computer Science\nURL: https://www.cs.cmu.edu/~abertsch/\nSnippet: I am a PhD student in the Language Technologies Institute at Carnegie Mellon University, advised by Matt Gormley and Graham Neubig.",
                "called": true,
                "timeout": false,
                "runtime": 1.3394029140472412,
                "error": "",
                "call_id": "a99f9efb",
                "raw_output": {
                  "searchParameters": {
                    "q": "CMU 11-763 Inference Algorithms for Language Modeling faculty contact information Graham Neubig Amanda Bertsch",
                    "gl": "us",
                    "hl": "en",
                    "type": "search",
                    "num": 2,
                    "engine": "google"
                  },
                  "organic": [
                    {
                      "title": "11-664/763: Inference Algorithms for Language Modeling",
                      "link": "https://www.phontron.com/class/lminference-fall2025/",
                      "snippet": "Graham Neubig \u00b7 gneubig@cs.cmu.edu \u00b7 Amanda Bertsch \u00b7 abertsch@cs.cmu.edu. Course ... Course Information. Prerequisites: 11-411/611/711 OR 11-785 OR 10-401/601 ...",
                      "attributes": {
                        "Missing": "faculty | Show results with:faculty"
                      },
                      "position": 1
                    },
                    {
                      "title": "Amanda Bertsch - CMU School of Computer Science",
                      "link": "https://www.cs.cmu.edu/~abertsch/",
                      "snippet": "I am a PhD student in the Language Technologies Institute at Carnegie Mellon University, advised by Matt Gormley and Graham Neubig.",
                      "attributes": {
                        "Missing": "11-763 faculty"
                      },
                      "position": 2
                    }
                  ],
                  "credits": 1
                },
                "documents": [
                  {
                    "id": "c15d3539-5251-4830-9748-f3fdcc4bb298",
                    "title": "11-664/763: Inference Algorithms for Language Modeling",
                    "url": "https://www.phontron.com/class/lminference-fall2025/",
                    "snippet": "Graham Neubig \u00b7 gneubig@cs.cmu.edu \u00b7 Amanda Bertsch \u00b7 abertsch@cs.cmu.edu. Course ... Course Information. Prerequisites: 11-411/611/711 OR 11-785 OR 10-401/601 ...",
                    "text": null,
                    "summary": null,
                    "score": null,
                    "error": null
                  },
                  {
                    "id": "134116a3-6634-4235-a9f9-6cecb6ab675f",
                    "title": "Amanda Bertsch - CMU School of Computer Science",
                    "url": "https://www.cs.cmu.edu/~abertsch/",
                    "snippet": "I am a PhD student in the Language Technologies Institute at Carnegie Mellon University, advised by Matt Gormley and Graham Neubig.",
                    "text": null,
                    "summary": null,
                    "score": null,
                    "error": null
                  }
                ],
                "query": "CMU 11-763 Inference Algorithms for Language Modeling faculty contact information Graham Neubig Amanda Bertsch"
              },
              {
                "tool_name": "Crawl4AIBrowseTool",
                "output": "Title: 11-664/763: Inference Algorithms for Language Modeling\nURL: https://www.phontron.com/class/lminference-fall2025/\nSnippet: Graham Neubig \u00b7 gneubig@cs.cmu.edu \u00b7 Amanda Bertsch \u00b7 abertsch@cs.cmu.edu. Course ... Course Information. Prerequisites: 11-411/611/711 OR 11-785 OR 10-401/601 ...\n\nTitle: Amanda Bertsch - CMU School of Computer Science\nURL: https://www.cs.cmu.edu/~abertsch/\nSnippet: I am a PhD student in the Language Technologies Institute at Carnegie Mellon University, advised by Matt Gormley and Graham Neubig.",
                "called": true,
                "timeout": false,
                "runtime": 1.9435760974884033,
                "error": "",
                "call_id": "5a9ca80c",
                "raw_output": null,
                "documents": [
                  {
                    "id": "c15d3539-5251-4830-9748-f3fdcc4bb298",
                    "title": "11-664/763: Inference Algorithms for Language Modeling",
                    "url": "https://www.phontron.com/class/lminference-fall2025/",
                    "snippet": "Graham Neubig \u00b7 gneubig@cs.cmu.edu \u00b7 Amanda Bertsch \u00b7 abertsch@cs.cmu.edu. Course ... Course Information. Prerequisites: 11-411/611/711 OR 11-785 OR 10-401/601 ...",
                    "text": "Skip to main content Link Menu Expand (external link) Document Search Copy Copied\n11-664/763 LM Inference \n#  11-664/763: Inference Algorithms for Language Modeling\nFall 2025 @ Carnegie Mellon University\n![](https://www.phontron.com/class/lminference-fall2025/assets/images/graham_neubig.jpeg)\n###  Graham Neubig\ngneubig@cs.cmu.edu\n![](https://www.phontron.com/class/lminference-fall2025/assets/images/abertsch.jpg)\n###  Amanda Bertsch\nabertsch@cs.cmu.edu\n##  Course Description\nAs the use of massive and costly-to-train large language models has become increasingly commonplace, much academic and industry interest has focused on the methods used to generate outputs from these models \u2013 the inference process. Inference-time algorithms can be applied on top of an already-trained model to improve generation quality, lower latency, or induce additional controllability. Inference-time algorithms can allow users to run models on their laptop, serve millions of outputs at scale, or dramatically increase the quality of generations from a system without additional training.\nIn this class, we survey the wide space of inference-time techniques with a particular focus on the implementation and practical use cases of such methods. Students will understand the different ways to implement and compare inference-time techniques, learn the theory behind different strategies for inference-time scaling of compute, and implement representative examples from several classes of inference-time algorithms. In the final project, students will apply inference-time strategies of their choice to two shared tasks: an open-ended generation task and a reasoning task.\n##  Course Information\n  * **Prerequisites** : 11-411/611/711 OR 11-785 OR 10-401/601/701 OR 10-715 OR 11-667\n  * **Target Audience** : Research masters or PhD students who have some basic knowledge of language models and NLP, are comfortable with programming in Python, and are interested in understanding language model inference from an algorithmic perspective\n  * **Class Size** : Capped at 45 students\n\n\n##  Quick Links\n  * Course Details\n  * Schedule\n  * Assignments\n  * Staff\n  * Posters\n\n\n",
                    "summary": null,
                    "score": null,
                    "error": null
                  },
                  {
                    "id": "134116a3-6634-4235-a9f9-6cecb6ab675f",
                    "title": "Amanda Bertsch - CMU School of Computer Science",
                    "url": "https://www.cs.cmu.edu/~abertsch/",
                    "snippet": "I am a PhD student in the Language Technologies Institute at Carnegie Mellon University, advised by Matt Gormley and Graham Neubig.",
                    "text": "![profile.jpg](https://www.cs.cmu.edu/~abertsch/assets/img/profile.jpg?534245c3dc2b04a94165673d90126030)\nI am a PhD student in the Language Technologies Institute at Carnegie Mellon University, advised by Matt Gormley and Graham Neubig. I am a member of NeuLab and an organizer for Queer in AI. I\u2019m fortunate to be funded by an NSF Graduate Research Fellowship.\nI work primarily on conditional generation, particularly long-context modeling and inference-time algorithms; my broader research interests include better ways to reason over large quantities of knowledge, model large-scale structure in text, and effectively integrate external knowledge into models. Currently, I\u2019m excited about evaluation for realistic long-context settings, more efficient model deployment, and understanding how community divergence affects whose work we engage with. I\u2019m also broadly interested in meta-analysis of the NLP community, including critically examining the benchmarks, datasets, and modeling choices we take as defaults.\nI\u2019m trying to get to know my academic neighbors! If we work on similar things (or very different things that might be connected in interesting ways), I\u2019d love to chat\u2013 please email me :)\nBefore coming to CMU, I received my bachelors in math and computer science from the University of Arizona, where I was advised by Steven Bethard. Before coming to NLP, I worked in soil microbiology, built large-scale Rube Goldberg machines, and occasionally published short fiction. In my spare time, I write and read speculative fiction, hike, run, and play tabletop games.\n##  news\nMar 10, 2025 |  I\u2019ll be presenting our work on long-context in-context learning at NAACL in Albuquerque!   \n---|---  \nFeb 15, 2025 |  And this summer (summer 2025), I\u2019ll be back in Seattle, interning with Dirk Groeneveld at AI2 and working on OLMo!   \nMay 15, 2024 |  I\u2019m interning this summer with Mike Lewis at Meta GenAI! Excited to spend the summer thinking about long context & hiking in Seattle :)   \nOct 24, 2023 |  Excited to announce some new work going to EMNLP: a qualitative study of the NLP community (main); a system for distilling a model from a single textual instruction (demo); and an analysis paper about Minimum Bayes Risk decoding, (Big Picture workshop)! Looking forward to seeing folks in Singapore.   \nJun 06, 2023 |  Check out our recent preprints: Unlimiformer, a long-range transformer and a survey on human feedback for generation! (Update September 2023: Unlimiformer was accepted to NeurIPS, and this survey was accepted to TACL!)   \n##  selected publications\n  1. preprint\nEfficient Many-Shot In-Context Learning with Dynamic Block-Sparse Attention\nEmily Xiao, Chin-Jou Li, Yilin Zhang, Graham Neubig, and  _Amanda Bertsch_\n_In [under submission]_ , 2025 \nPDF\n  2. NAACL\nIn-context learning with long-context models: An in-depth exploration\n_Amanda Bertsch_ , Maor Ivgi, Uri Alon, Jonathan Berant, Matthew R Gormley, and Graham Neubig \n_In 2025 Annual Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics_ , 2025 \nPDF\n  3. TMLR\nFrom Decoding to Meta-Generation: Inference-time Algorithms for Large Language Models\nSean Welleck,  _Amanda Bertsch_ , Matthew Finlayson, Hailey Schoelkopf, Alex Xie, Graham Neubig, and 2 more authors\n_In Transactions on Machine Learning Research_ , 2024 \nPDF\n  4. EMNLP\nTo Build Our Future, We Must Know Our Past: Contextualizing Paradigm Shifts in Natural Language Processing\nSireesh Gururaja,  _Amanda Bertsch_ , Clara Na, David Gray Widder, and Emma Strubell \n_In Empirical Methods in Natural Language Processing._ , 2023 \nPDF\n  5. NeurIPS\nUnlimiformer: Long-Range Transformers with Unlimited Length Input\n_Amanda Bertsch_ , Uri Alon, Graham Neubig, and Matthew R. Gormley \n_In Conference on Neural Information Processing Systems._ , 2023 \nPDF\n\n\nEmail or openNLP slack preferred! \n",
                    "summary": null,
                    "score": null,
                    "error": null
                  }
                ],
                "query": "CMU 11-763 Inference Algorithms for Language Modeling faculty contact information Graham Neubig Amanda Bertsch"
              }
            ],
            "failed_at": null,
            "expected_tool_calls": 2,
            "total_tool_calls": 2,
            "total_failed_tool_calls": 0
          }
        },
        {
          "tool_name": "ChainedTool",
          "output": "Title: 11-664/763: Inference Algorithms for Language Modeling\nURL: https://www.phontron.com/class/lminference-fall2025/\nSnippet: In this class, we survey the wide space of inference-time techniques with a particular focus on the implementation and practical use cases of such methods.\n\nTitle: Learn Inference Algorithms for Language Modeling at CMU - LinkedIn\nURL: https://www.linkedin.com/posts/kelvinmeeks_11-663763-lm-inference-activity-7341239778308214786-5NXw\nSnippet: Noteworthy: 11-663/763: Inference Algorithms for Language Modeling Fall 2025 Carnegie Mellon University Taught by Graham Neubig, and Amanda ...",
          "called": true,
          "timeout": false,
          "runtime": 2.569354772567749,
          "error": "",
          "call_id": "30101cdd",
          "raw_output": {
            "tool_outputs": [
              {
                "tool_name": "SerperSearchTool",
                "output": "Title: 11-664/763: Inference Algorithms for Language Modeling\nURL: https://www.phontron.com/class/lminference-fall2025/\nSnippet: In this class, we survey the wide space of inference-time techniques with a particular focus on the implementation and practical use cases of such methods.\n\nTitle: Learn Inference Algorithms for Language Modeling at CMU - LinkedIn\nURL: https://www.linkedin.com/posts/kelvinmeeks_11-663763-lm-inference-activity-7341239778308214786-5NXw\nSnippet: Noteworthy: 11-663/763: Inference Algorithms for Language Modeling Fall 2025 Carnegie Mellon University Taught by Graham Neubig, and Amanda ...",
                "called": true,
                "timeout": false,
                "runtime": 0.9748928546905518,
                "error": "",
                "call_id": "4bc71157",
                "raw_output": {
                  "searchParameters": {
                    "q": "CMU 11-763 Inference Algorithms for Language Modeling staff members Graham Neubig Amanda Bertsch course details",
                    "gl": "us",
                    "hl": "en",
                    "type": "search",
                    "num": 2,
                    "engine": "google"
                  },
                  "organic": [
                    {
                      "title": "11-664/763: Inference Algorithms for Language Modeling",
                      "link": "https://www.phontron.com/class/lminference-fall2025/",
                      "snippet": "In this class, we survey the wide space of inference-time techniques with a particular focus on the implementation and practical use cases of such methods.",
                      "attributes": {
                        "Missing": "members | Show results with:members"
                      },
                      "position": 1
                    },
                    {
                      "title": "Learn Inference Algorithms for Language Modeling at CMU - LinkedIn",
                      "link": "https://www.linkedin.com/posts/kelvinmeeks_11-663763-lm-inference-activity-7341239778308214786-5NXw",
                      "snippet": "Noteworthy: 11-663/763: Inference Algorithms for Language Modeling Fall 2025 Carnegie Mellon University Taught by Graham Neubig, and Amanda ...",
                      "date": "Jun 18, 2025",
                      "attributes": {
                        "Missing": "staff details"
                      },
                      "position": 2
                    }
                  ],
                  "credits": 1
                },
                "documents": [
                  {
                    "id": "ecd37ebd-66c5-4d33-8784-9f2716c7ce65",
                    "title": "11-664/763: Inference Algorithms for Language Modeling",
                    "url": "https://www.phontron.com/class/lminference-fall2025/",
                    "snippet": "In this class, we survey the wide space of inference-time techniques with a particular focus on the implementation and practical use cases of such methods.",
                    "text": null,
                    "summary": null,
                    "score": null,
                    "error": null
                  },
                  {
                    "id": "5f7b40ce-a2b1-4d21-bf27-543762f22314",
                    "title": "Learn Inference Algorithms for Language Modeling at CMU - LinkedIn",
                    "url": "https://www.linkedin.com/posts/kelvinmeeks_11-663763-lm-inference-activity-7341239778308214786-5NXw",
                    "snippet": "Noteworthy: 11-663/763: Inference Algorithms for Language Modeling Fall 2025 Carnegie Mellon University Taught by Graham Neubig, and Amanda ...",
                    "text": null,
                    "summary": null,
                    "score": null,
                    "error": null
                  }
                ],
                "query": "CMU 11-763 Inference Algorithms for Language Modeling staff members Graham Neubig Amanda Bertsch course details"
              },
              {
                "tool_name": "Crawl4AIBrowseTool",
                "output": "Title: 11-664/763: Inference Algorithms for Language Modeling\nURL: https://www.phontron.com/class/lminference-fall2025/\nSnippet: In this class, we survey the wide space of inference-time techniques with a particular focus on the implementation and practical use cases of such methods.\n\nTitle: Learn Inference Algorithms for Language Modeling at CMU - LinkedIn\nURL: https://www.linkedin.com/posts/kelvinmeeks_11-663763-lm-inference-activity-7341239778308214786-5NXw\nSnippet: Noteworthy: 11-663/763: Inference Algorithms for Language Modeling Fall 2025 Carnegie Mellon University Taught by Graham Neubig, and Amanda ...",
                "called": true,
                "timeout": false,
                "runtime": 1.5943949222564697,
                "error": "",
                "call_id": "56ecb5e0",
                "raw_output": null,
                "documents": [
                  {
                    "id": "ecd37ebd-66c5-4d33-8784-9f2716c7ce65",
                    "title": "11-664/763: Inference Algorithms for Language Modeling",
                    "url": "https://www.phontron.com/class/lminference-fall2025/",
                    "snippet": "In this class, we survey the wide space of inference-time techniques with a particular focus on the implementation and practical use cases of such methods.",
                    "text": "Skip to main content Link Menu Expand (external link) Document Search Copy Copied\n11-664/763 LM Inference \n#  11-664/763: Inference Algorithms for Language Modeling\nFall 2025 @ Carnegie Mellon University\n![](https://www.phontron.com/class/lminference-fall2025/assets/images/graham_neubig.jpeg)\n###  Graham Neubig\ngneubig@cs.cmu.edu\n![](https://www.phontron.com/class/lminference-fall2025/assets/images/abertsch.jpg)\n###  Amanda Bertsch\nabertsch@cs.cmu.edu\n##  Course Description\nAs the use of massive and costly-to-train large language models has become increasingly commonplace, much academic and industry interest has focused on the methods used to generate outputs from these models \u2013 the inference process. Inference-time algorithms can be applied on top of an already-trained model to improve generation quality, lower latency, or induce additional controllability. Inference-time algorithms can allow users to run models on their laptop, serve millions of outputs at scale, or dramatically increase the quality of generations from a system without additional training.\nIn this class, we survey the wide space of inference-time techniques with a particular focus on the implementation and practical use cases of such methods. Students will understand the different ways to implement and compare inference-time techniques, learn the theory behind different strategies for inference-time scaling of compute, and implement representative examples from several classes of inference-time algorithms. In the final project, students will apply inference-time strategies of their choice to two shared tasks: an open-ended generation task and a reasoning task.\n##  Course Information\n  * **Prerequisites** : 11-411/611/711 OR 11-785 OR 10-401/601/701 OR 10-715 OR 11-667\n  * **Target Audience** : Research masters or PhD students who have some basic knowledge of language models and NLP, are comfortable with programming in Python, and are interested in understanding language model inference from an algorithmic perspective\n  * **Class Size** : Capped at 45 students\n\n\n##  Quick Links\n  * Course Details\n  * Schedule\n  * Assignments\n  * Staff\n  * Posters\n\n\n",
                    "summary": null,
                    "score": null,
                    "error": null
                  },
                  {
                    "id": "5f7b40ce-a2b1-4d21-bf27-543762f22314",
                    "title": "Learn Inference Algorithms for Language Modeling at CMU - LinkedIn",
                    "url": "https://www.linkedin.com/posts/kelvinmeeks_11-663763-lm-inference-activity-7341239778308214786-5NXw",
                    "snippet": "Noteworthy: 11-663/763: Inference Algorithms for Language Modeling Fall 2025 Carnegie Mellon University Taught by Graham Neubig, and Amanda ...",
                    "text": "`` `` `` `` `` `` Skip to main content \n#  Learn Inference Algorithms for Language Modeling at CMU\nThis title was summarized by AI from the post below.\nKelvin Meeks \nConsulting Architect/CTO - Leadership in Enterprise Architecture and Software Engineering Innovation (US Army Veteran) \n4mo  Edited \n  * \n\nNoteworthy: 11-663/763: Inference Algorithms for Language Modeling Fall 2025 Carnegie Mellon University Taught by Graham Neubig, and Amanda Bertsch \"Inference-time algorithms can allow users to run models on their laptop, serve millions of outputs at scale, or dramatically increase the quality of generations from a system without additional training.\" \"In this class, we survey the wide space of inference-time techniques with a particular focus on the implementation and practical use cases of such methods. Students will understand the different ways to implement and compare inference-time techniques, learn the theory behind different strategies for inference-time scaling of compute, and implement representative examples from several classes of inference-time algorithms. In the final project, students will apply inference-time strategies of their choice to two shared tasks: an open-ended generation task and a reasoning task.\" https://lnkd.in/gtn2rrsc\n`` ``\nLike  Comment  `` ``\nShare \n  * Copy\n  * LinkedIn\n  * Facebook\n  * X\n\n\nTo view or add a comment, sign in\n``\n![](https://media.licdn.com/dms/image/v2/D5616AQEEuon8PR5GEA/profile-displaybackgroundimage-shrink_200_800/B56Zn.gfFqI4AU-/0/1760911553925?e=2147483647&v=beta&t=k9SuklukXirkp3DRDZIxpyjPuzAcPkjFVtYTDSgsK9I)\n6,557 followers \n  * 2,880 Posts \n  * 20 Articles \n\n\nView Profile  Follow\n##  More from this author \n  * ###  Trusting Your Intuition - Though You May Stand Alone \nKelvin Meeks  3y \n  * ###  Why Your Pitch Failed \nKelvin Meeks  4y \n  * ###  Remember, There Is No Free Lunch \nKelvin Meeks  5y \n\n\n##  Explore content categories \n  * Career\n  * Productivity\n  * Finance\n  * Soft Skills & Emotional Intelligence\n  * Project Management\n  * Education\n  * Technology\n  * Leadership\n  * Ecommerce\n  * User Experience\n\nShow more  Show less \n##  Sign in to view more content \nCreate your free account or sign in to continue your search \nSign in \n##  Welcome back \n`` `` `` `` `` `` `` `` `` ``\nBy clicking Continue to join or sign in, you agree to LinkedIn\u2019s User Agreement, Privacy Policy, and Cookie Policy. \nNew to LinkedIn? Join now\nor \nNew to LinkedIn? Join now\nBy clicking Continue to join or sign in, you agree to LinkedIn\u2019s User Agreement, Privacy Policy, and Cookie Policy. \n``\n",
                    "summary": null,
                    "score": null,
                    "error": null
                  }
                ],
                "query": "CMU 11-763 Inference Algorithms for Language Modeling staff members Graham Neubig Amanda Bertsch course details"
              }
            ],
            "failed_at": null,
            "expected_tool_calls": 2,
            "total_tool_calls": 2,
            "total_failed_tool_calls": 0
          }
        },
        {
          "tool_name": "ChainedTool",
          "output": "Title: 11-664/763: Inference Algorithms for Language Modeling\nURL: https://www.phontron.com/class/lminference-fall2025/\nSnippet: A class at Carnegie Mellon University on language model inference algorithms ... Graham Neubig \u00b7 gneubig@cs.cmu.edu \u00b7 Amanda Bertsch \u00b7 abertsch@cs.cmu.edu. Course ...\n\nTitle: Graham Neubig - Language Technologies Institute\nURL: https://www.lti.cs.cmu.edu/people/faculty/neubig-graham.html\nSnippet: Graham Neubig is an associate professor at the Language Technologies Institute of Carnegie Mellon University. His research focuses on natural language ...",
          "called": true,
          "timeout": false,
          "runtime": 2.8012378215789795,
          "error": "",
          "call_id": "68079351",
          "raw_output": {
            "tool_outputs": [
              {
                "tool_name": "SerperSearchTool",
                "output": "Title: 11-664/763: Inference Algorithms for Language Modeling\nURL: https://www.phontron.com/class/lminference-fall2025/\nSnippet: A class at Carnegie Mellon University on language model inference algorithms ... Graham Neubig \u00b7 gneubig@cs.cmu.edu \u00b7 Amanda Bertsch \u00b7 abertsch@cs.cmu.edu. Course ...\n\nTitle: Graham Neubig - Language Technologies Institute\nURL: https://www.lti.cs.cmu.edu/people/faculty/neubig-graham.html\nSnippet: Graham Neubig is an associate professor at the Language Technologies Institute of Carnegie Mellon University. His research focuses on natural language ...",
                "called": true,
                "timeout": false,
                "runtime": 1.0019207000732422,
                "error": "",
                "call_id": "568de665",
                "raw_output": {
                  "searchParameters": {
                    "q": "CMU 11-763 Inference Algorithms for Language Modeling course staff instructors Graham Neubig Amanda Bertsch",
                    "gl": "us",
                    "hl": "en",
                    "type": "search",
                    "num": 2,
                    "engine": "google"
                  },
                  "organic": [
                    {
                      "title": "11-664/763: Inference Algorithms for Language Modeling",
                      "link": "https://www.phontron.com/class/lminference-fall2025/",
                      "snippet": "A class at Carnegie Mellon University on language model inference algorithms ... Graham Neubig \u00b7 gneubig@cs.cmu.edu \u00b7 Amanda Bertsch \u00b7 abertsch@cs.cmu.edu. Course ...",
                      "attributes": {
                        "Missing": "instructors | Show results with:instructors"
                      },
                      "position": 1
                    },
                    {
                      "title": "Graham Neubig - Language Technologies Institute",
                      "link": "https://www.lti.cs.cmu.edu/people/faculty/neubig-graham.html",
                      "snippet": "Graham Neubig is an associate professor at the Language Technologies Institute of Carnegie Mellon University. His research focuses on natural language ...",
                      "position": 2
                    }
                  ],
                  "credits": 1
                },
                "documents": [
                  {
                    "id": "603c8714-60bc-44b3-b57e-6844f5a0454f",
                    "title": "11-664/763: Inference Algorithms for Language Modeling",
                    "url": "https://www.phontron.com/class/lminference-fall2025/",
                    "snippet": "A class at Carnegie Mellon University on language model inference algorithms ... Graham Neubig \u00b7 gneubig@cs.cmu.edu \u00b7 Amanda Bertsch \u00b7 abertsch@cs.cmu.edu. Course ...",
                    "text": null,
                    "summary": null,
                    "score": null,
                    "error": null
                  },
                  {
                    "id": "73fea3ba-e007-40de-88f9-2b3dc2a1ad1c",
                    "title": "Graham Neubig - Language Technologies Institute",
                    "url": "https://www.lti.cs.cmu.edu/people/faculty/neubig-graham.html",
                    "snippet": "Graham Neubig is an associate professor at the Language Technologies Institute of Carnegie Mellon University. His research focuses on natural language ...",
                    "text": null,
                    "summary": null,
                    "score": null,
                    "error": null
                  }
                ],
                "query": "CMU 11-763 Inference Algorithms for Language Modeling course staff instructors Graham Neubig Amanda Bertsch"
              },
              {
                "tool_name": "Crawl4AIBrowseTool",
                "output": "Title: 11-664/763: Inference Algorithms for Language Modeling\nURL: https://www.phontron.com/class/lminference-fall2025/\nSnippet: A class at Carnegie Mellon University on language model inference algorithms ... Graham Neubig \u00b7 gneubig@cs.cmu.edu \u00b7 Amanda Bertsch \u00b7 abertsch@cs.cmu.edu. Course ...\n\nTitle: Graham Neubig - Language Technologies Institute\nURL: https://www.lti.cs.cmu.edu/people/faculty/neubig-graham.html\nSnippet: Graham Neubig is an associate professor at the Language Technologies Institute of Carnegie Mellon University. His research focuses on natural language ...",
                "called": true,
                "timeout": false,
                "runtime": 1.7992169857025146,
                "error": "",
                "call_id": "21104ece",
                "raw_output": null,
                "documents": [
                  {
                    "id": "603c8714-60bc-44b3-b57e-6844f5a0454f",
                    "title": "11-664/763: Inference Algorithms for Language Modeling",
                    "url": "https://www.phontron.com/class/lminference-fall2025/",
                    "snippet": "A class at Carnegie Mellon University on language model inference algorithms ... Graham Neubig \u00b7 gneubig@cs.cmu.edu \u00b7 Amanda Bertsch \u00b7 abertsch@cs.cmu.edu. Course ...",
                    "text": "Skip to main content Link Menu Expand (external link) Document Search Copy Copied\n11-664/763 LM Inference \n#  11-664/763: Inference Algorithms for Language Modeling\nFall 2025 @ Carnegie Mellon University\n![](https://www.phontron.com/class/lminference-fall2025/assets/images/graham_neubig.jpeg)\n###  Graham Neubig\ngneubig@cs.cmu.edu\n![](https://www.phontron.com/class/lminference-fall2025/assets/images/abertsch.jpg)\n###  Amanda Bertsch\nabertsch@cs.cmu.edu\n##  Course Description\nAs the use of massive and costly-to-train large language models has become increasingly commonplace, much academic and industry interest has focused on the methods used to generate outputs from these models \u2013 the inference process. Inference-time algorithms can be applied on top of an already-trained model to improve generation quality, lower latency, or induce additional controllability. Inference-time algorithms can allow users to run models on their laptop, serve millions of outputs at scale, or dramatically increase the quality of generations from a system without additional training.\nIn this class, we survey the wide space of inference-time techniques with a particular focus on the implementation and practical use cases of such methods. Students will understand the different ways to implement and compare inference-time techniques, learn the theory behind different strategies for inference-time scaling of compute, and implement representative examples from several classes of inference-time algorithms. In the final project, students will apply inference-time strategies of their choice to two shared tasks: an open-ended generation task and a reasoning task.\n##  Course Information\n  * **Prerequisites** : 11-411/611/711 OR 11-785 OR 10-401/601/701 OR 10-715 OR 11-667\n  * **Target Audience** : Research masters or PhD students who have some basic knowledge of language models and NLP, are comfortable with programming in Python, and are interested in understanding language model inference from an algorithmic perspective\n  * **Class Size** : Capped at 45 students\n\n\n##  Quick Links\n  * Course Details\n  * Schedule\n  * Assignments\n  * Staff\n  * Posters\n\n\n",
                    "summary": null,
                    "score": null,
                    "error": null
                  },
                  {
                    "id": "73fea3ba-e007-40de-88f9-2b3dc2a1ad1c",
                    "title": "Graham Neubig - Language Technologies Institute",
                    "url": "https://www.lti.cs.cmu.edu/people/faculty/neubig-graham.html",
                    "snippet": "Graham Neubig is an associate professor at the Language Technologies Institute of Carnegie Mellon University. His research focuses on natural language ...",
                    "text": "![](https://www.cmu.edu/common/standard-v6/images/cmu-wordmark.png)\nSkip to main content\nSchool of Computer Science \u203a Language Technologies Institute \u203a  People  \u203a  Faculty  \u203a Graham Neubig \n![Graham Neubig](https://www.lti.cs.cmu.edu/people/faculty/faculty-bio-images/neubig-headshot-2021.jpg)\n#  Graham Neubig \n##  Associate Professor, Language Technologies Institute \nContact\n  * 5409 Gates & Hillman Centers\n  * Email\n\n\n  * Personal Website\n\n\n**Graham Neubig** is an associate professor at the Language Technologies Institute of Carnegie Mellon University. His research focuses on natural language processing and large language models, including both fundamental advances in model capabilities and applications to tasks such as software development. His final goal is that every person in the world should be able to communicate with each-other, and with computers in their own language. He also contributes to making NLP research more accessible through open publishing of research papers, advanced NLP course materials and video lectures, and open-source software, all of which are available on his web site.\n## Research Areas\n  * Embodiment\n  * Grounding\n  * RoboNLP\n  * Unsupervised Learning\n  * Vision and Language\n\n\n## Research Statement\nMy research is concerned with language and its role in human communication. In particular, my long-term research goal is to break down barriers in human-human or human-machine communication through the development of natural language processing (NLP) technologies. This includes the development of technology for machine translation, which helps break down barriers in communication for people who speak different languages, and natural language understanding, which helps computers understand and respond to human language. Within this overall goal of breaking down barriers to human communication, I have focused on several aspects of language that both make it interesting as a scientific subject, and hold potential for the construction of practical systems.\nAdvances in core NLP technology: Human language is complex and nuanced, and handling this complexity in a computational way requires sophisticated algorithms or learning techniques, the development of which is far from a solved problem. The first major area of my work focuses on advances in core NLP technology, which improve the accuracy with which we can analyze, translate, generate, or reply to textual inputs. \nModels of language associated with other modalities: Human language does not exist in a vacuum, and is often associated with context from the world around it. The second thread of my research focuses on models of natural language associated with other modalities, tackling the problems, and exploiting the fascinating possibilities presented by having text associated with other types of information. Specifically, I have worked extensively with speech, and am also interested in associations between natural and formal languages such as source code.\nLearning from naturally occurring data: Language data exists in abundance, particularly due to the advent of the internet, and it is possible to acquire extremely large amounts of this data for scientific or engineering purposes. A third thread of my research focuses on learning NLP models from naturally occurring data through the use of unsupervised, semi-supervised, or active learning, which allows us to exploit this data to improve models while reducing the necessity for costly manual annotation.\n## Teaching\n**Spring 2025**\n  * 11967 - Large Language Models: Methods and Application\n\n\n**Fall 2025**\n  * 11-664/763 - Inference Algorithms for Language Modeling\n\n\n# Advisees\n  * Amanda Bertsch\n  * Patrick Fernandes\n  * Anjali Kantharuban\n  * Simran Khanuja\n  * Seungone Kim\n  * Emmy Liu\n  * Lintang Sutawika\n  * Lindia Tjuatja\n  * Vijay Viswanathan\n  * Zhiruo Wang\n  * Fangzheng Xu\n\n\n#  In the News \n![print](https://www.lti.cs.cmu.edu/news-and-events/news/news-story-photos/emnlp-simran.png)\n## LTI Authors Win Dual Best Paper Awards at EMNLP\n![print](https://www.lti.cs.cmu.edu/images/neubig-headshot-fav.jpg)\n## Neubig Named Finalist for Blavatnik National Awards for Young Scientists\n![print](https://www.lti.cs.cmu.edu/news-and-events/news/news-story-photos/ai-fairness-markus-winkler-wpoa2i3mury-unsplash.jpg)\n## Neubig Among Three CMU Winners of NSF-Amazon Fairness in AI Award\n\u25b4\n",
                    "summary": null,
                    "score": null,
                    "error": null
                  }
                ],
                "query": "CMU 11-763 Inference Algorithms for Language Modeling course staff instructors Graham Neubig Amanda Bertsch"
              }
            ],
            "failed_at": null,
            "expected_tool_calls": 2,
            "total_tool_calls": 2,
            "total_failed_tool_calls": 0
          }
        },
        {
          "tool_name": "ChainedTool",
          "output": "Title: 11-664/763: Inference Algorithms for Language Modeling\nURL: https://www.phontron.com/class/lminference-fall2025/\nSnippet: A class at Carnegie Mellon University on language model inference algorithms ... Graham Neubig \u00b7 gneubig@cs.cmu.edu \u00b7 Amanda Bertsch \u00b7 abertsch@cs.cmu.edu. Course ...\n\nTitle: Graham Neubig - Language Technologies Institute\nURL: https://www.lti.cs.cmu.edu/people/faculty/neubig-graham.html\nSnippet: Graham Neubig is an associate professor at the Language Technologies Institute of Carnegie Mellon University. His research focuses on natural language ...",
          "called": true,
          "timeout": false,
          "runtime": 2.5705127716064453,
          "error": "",
          "call_id": "6309c263",
          "raw_output": {
            "tool_outputs": [
              {
                "tool_name": "SerperSearchTool",
                "output": "Title: 11-664/763: Inference Algorithms for Language Modeling\nURL: https://www.phontron.com/class/lminference-fall2025/\nSnippet: A class at Carnegie Mellon University on language model inference algorithms ... Graham Neubig \u00b7 gneubig@cs.cmu.edu \u00b7 Amanda Bertsch \u00b7 abertsch@cs.cmu.edu. Course ...\n\nTitle: Graham Neubig - Language Technologies Institute\nURL: https://www.lti.cs.cmu.edu/people/faculty/neubig-graham.html\nSnippet: Graham Neubig is an associate professor at the Language Technologies Institute of Carnegie Mellon University. His research focuses on natural language ...",
                "called": true,
                "timeout": false,
                "runtime": 0.8317217826843262,
                "error": "",
                "call_id": "d5474df1",
                "raw_output": {
                  "searchParameters": {
                    "q": "CMU 11-763 Inference Algorithms for Language Modeling faculty Graham Neubig Amanda Bertsch information",
                    "gl": "us",
                    "hl": "en",
                    "type": "search",
                    "num": 2,
                    "engine": "google"
                  },
                  "organic": [
                    {
                      "title": "11-664/763: Inference Algorithms for Language Modeling",
                      "link": "https://www.phontron.com/class/lminference-fall2025/",
                      "snippet": "A class at Carnegie Mellon University on language model inference algorithms ... Graham Neubig \u00b7 gneubig@cs.cmu.edu \u00b7 Amanda Bertsch \u00b7 abertsch@cs.cmu.edu. Course ...",
                      "attributes": {
                        "Missing": "faculty | Show results with:faculty"
                      },
                      "position": 1
                    },
                    {
                      "title": "Graham Neubig - Language Technologies Institute",
                      "link": "https://www.lti.cs.cmu.edu/people/faculty/neubig-graham.html",
                      "snippet": "Graham Neubig is an associate professor at the Language Technologies Institute of Carnegie Mellon University. His research focuses on natural language ...",
                      "position": 2
                    }
                  ],
                  "credits": 1
                },
                "documents": [
                  {
                    "id": "11bb005c-70bc-4ed7-831d-c804fc0baeee",
                    "title": "11-664/763: Inference Algorithms for Language Modeling",
                    "url": "https://www.phontron.com/class/lminference-fall2025/",
                    "snippet": "A class at Carnegie Mellon University on language model inference algorithms ... Graham Neubig \u00b7 gneubig@cs.cmu.edu \u00b7 Amanda Bertsch \u00b7 abertsch@cs.cmu.edu. Course ...",
                    "text": null,
                    "summary": null,
                    "score": null,
                    "error": null
                  },
                  {
                    "id": "046bea9e-07ef-407f-9980-a9781bde0197",
                    "title": "Graham Neubig - Language Technologies Institute",
                    "url": "https://www.lti.cs.cmu.edu/people/faculty/neubig-graham.html",
                    "snippet": "Graham Neubig is an associate professor at the Language Technologies Institute of Carnegie Mellon University. His research focuses on natural language ...",
                    "text": null,
                    "summary": null,
                    "score": null,
                    "error": null
                  }
                ],
                "query": "CMU 11-763 Inference Algorithms for Language Modeling faculty Graham Neubig Amanda Bertsch information"
              },
              {
                "tool_name": "Crawl4AIBrowseTool",
                "output": "Title: 11-664/763: Inference Algorithms for Language Modeling\nURL: https://www.phontron.com/class/lminference-fall2025/\nSnippet: A class at Carnegie Mellon University on language model inference algorithms ... Graham Neubig \u00b7 gneubig@cs.cmu.edu \u00b7 Amanda Bertsch \u00b7 abertsch@cs.cmu.edu. Course ...\n\nTitle: Graham Neubig - Language Technologies Institute\nURL: https://www.lti.cs.cmu.edu/people/faculty/neubig-graham.html\nSnippet: Graham Neubig is an associate professor at the Language Technologies Institute of Carnegie Mellon University. His research focuses on natural language ...",
                "called": true,
                "timeout": false,
                "runtime": 1.7387137413024902,
                "error": "",
                "call_id": "c38440e2",
                "raw_output": null,
                "documents": [
                  {
                    "id": "11bb005c-70bc-4ed7-831d-c804fc0baeee",
                    "title": "11-664/763: Inference Algorithms for Language Modeling",
                    "url": "https://www.phontron.com/class/lminference-fall2025/",
                    "snippet": "A class at Carnegie Mellon University on language model inference algorithms ... Graham Neubig \u00b7 gneubig@cs.cmu.edu \u00b7 Amanda Bertsch \u00b7 abertsch@cs.cmu.edu. Course ...",
                    "text": "Skip to main content Link Menu Expand (external link) Document Search Copy Copied\n11-664/763 LM Inference \n#  11-664/763: Inference Algorithms for Language Modeling\nFall 2025 @ Carnegie Mellon University\n![](https://www.phontron.com/class/lminference-fall2025/assets/images/graham_neubig.jpeg)\n###  Graham Neubig\ngneubig@cs.cmu.edu\n![](https://www.phontron.com/class/lminference-fall2025/assets/images/abertsch.jpg)\n###  Amanda Bertsch\nabertsch@cs.cmu.edu\n##  Course Description\nAs the use of massive and costly-to-train large language models has become increasingly commonplace, much academic and industry interest has focused on the methods used to generate outputs from these models \u2013 the inference process. Inference-time algorithms can be applied on top of an already-trained model to improve generation quality, lower latency, or induce additional controllability. Inference-time algorithms can allow users to run models on their laptop, serve millions of outputs at scale, or dramatically increase the quality of generations from a system without additional training.\nIn this class, we survey the wide space of inference-time techniques with a particular focus on the implementation and practical use cases of such methods. Students will understand the different ways to implement and compare inference-time techniques, learn the theory behind different strategies for inference-time scaling of compute, and implement representative examples from several classes of inference-time algorithms. In the final project, students will apply inference-time strategies of their choice to two shared tasks: an open-ended generation task and a reasoning task.\n##  Course Information\n  * **Prerequisites** : 11-411/611/711 OR 11-785 OR 10-401/601/701 OR 10-715 OR 11-667\n  * **Target Audience** : Research masters or PhD students who have some basic knowledge of language models and NLP, are comfortable with programming in Python, and are interested in understanding language model inference from an algorithmic perspective\n  * **Class Size** : Capped at 45 students\n\n\n##  Quick Links\n  * Course Details\n  * Schedule\n  * Assignments\n  * Staff\n  * Posters\n\n\n",
                    "summary": null,
                    "score": null,
                    "error": null
                  },
                  {
                    "id": "046bea9e-07ef-407f-9980-a9781bde0197",
                    "title": "Graham Neubig - Language Technologies Institute",
                    "url": "https://www.lti.cs.cmu.edu/people/faculty/neubig-graham.html",
                    "snippet": "Graham Neubig is an associate professor at the Language Technologies Institute of Carnegie Mellon University. His research focuses on natural language ...",
                    "text": "![](https://www.cmu.edu/common/standard-v6/images/cmu-wordmark.png)\nSkip to main content\nSchool of Computer Science \u203a Language Technologies Institute \u203a  People  \u203a  Faculty  \u203a Graham Neubig \n![Graham Neubig](https://www.lti.cs.cmu.edu/people/faculty/faculty-bio-images/neubig-headshot-2021.jpg)\n#  Graham Neubig \n##  Associate Professor, Language Technologies Institute \nContact\n  * 5409 Gates & Hillman Centers\n  * Email\n\n\n  * Personal Website\n\n\n**Graham Neubig** is an associate professor at the Language Technologies Institute of Carnegie Mellon University. His research focuses on natural language processing and large language models, including both fundamental advances in model capabilities and applications to tasks such as software development. His final goal is that every person in the world should be able to communicate with each-other, and with computers in their own language. He also contributes to making NLP research more accessible through open publishing of research papers, advanced NLP course materials and video lectures, and open-source software, all of which are available on his web site.\n## Research Areas\n  * Embodiment\n  * Grounding\n  * RoboNLP\n  * Unsupervised Learning\n  * Vision and Language\n\n\n## Research Statement\nMy research is concerned with language and its role in human communication. In particular, my long-term research goal is to break down barriers in human-human or human-machine communication through the development of natural language processing (NLP) technologies. This includes the development of technology for machine translation, which helps break down barriers in communication for people who speak different languages, and natural language understanding, which helps computers understand and respond to human language. Within this overall goal of breaking down barriers to human communication, I have focused on several aspects of language that both make it interesting as a scientific subject, and hold potential for the construction of practical systems.\nAdvances in core NLP technology: Human language is complex and nuanced, and handling this complexity in a computational way requires sophisticated algorithms or learning techniques, the development of which is far from a solved problem. The first major area of my work focuses on advances in core NLP technology, which improve the accuracy with which we can analyze, translate, generate, or reply to textual inputs. \nModels of language associated with other modalities: Human language does not exist in a vacuum, and is often associated with context from the world around it. The second thread of my research focuses on models of natural language associated with other modalities, tackling the problems, and exploiting the fascinating possibilities presented by having text associated with other types of information. Specifically, I have worked extensively with speech, and am also interested in associations between natural and formal languages such as source code.\nLearning from naturally occurring data: Language data exists in abundance, particularly due to the advent of the internet, and it is possible to acquire extremely large amounts of this data for scientific or engineering purposes. A third thread of my research focuses on learning NLP models from naturally occurring data through the use of unsupervised, semi-supervised, or active learning, which allows us to exploit this data to improve models while reducing the necessity for costly manual annotation.\n## Teaching\n**Spring 2025**\n  * 11967 - Large Language Models: Methods and Application\n\n\n**Fall 2025**\n  * 11-664/763 - Inference Algorithms for Language Modeling\n\n\n# Advisees\n  * Amanda Bertsch\n  * Patrick Fernandes\n  * Anjali Kantharuban\n  * Simran Khanuja\n  * Seungone Kim\n  * Emmy Liu\n  * Lintang Sutawika\n  * Lindia Tjuatja\n  * Vijay Viswanathan\n  * Zhiruo Wang\n  * Fangzheng Xu\n\n\n#  In the News \n![print](https://www.lti.cs.cmu.edu/news-and-events/news/news-story-photos/emnlp-simran.png)\n## LTI Authors Win Dual Best Paper Awards at EMNLP\n![print](https://www.lti.cs.cmu.edu/images/neubig-headshot-fav.jpg)\n## Neubig Named Finalist for Blavatnik National Awards for Young Scientists\n![print](https://www.lti.cs.cmu.edu/news-and-events/news/news-story-photos/ai-fairness-markus-winkler-wpoa2i3mury-unsplash.jpg)\n## Neubig Among Three CMU Winners of NSF-Amazon Fairness in AI Award\n\u25b4\n",
                    "summary": null,
                    "score": null,
                    "error": null
                  }
                ],
                "query": "CMU 11-763 Inference Algorithms for Language Modeling faculty Graham Neubig Amanda Bertsch information"
              }
            ],
            "failed_at": null,
            "expected_tool_calls": 2,
            "total_tool_calls": 2,
            "total_failed_tool_calls": 0
          }
        }
      ]
    },
    {
      "generated_text": "",
      "total_tokens": 2075,
      "tool_call_count": 0,
      "stopped_reason": "max_tokens",
      "tool_calls": []
    },
    {
      "generated_text": "",
      "total_tokens": 3650,
      "tool_call_count": 0,
      "stopped_reason": "max_tokens",
      "tool_calls": []
    },
    {
      "generated_text": "",
      "total_tokens": 2075,
      "tool_call_count": 0,
      "stopped_reason": "max_tokens",
      "tool_calls": []
    },
    {
      "generated_text": "",
      "total_tokens": 3652,
      "tool_call_count": 0,
      "stopped_reason": "max_tokens",
      "tool_calls": []
    }
  ]
}